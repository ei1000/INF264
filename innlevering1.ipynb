{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce77f734-cae6-4ec2-aace-df325a9cd059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import neighbors, datasets, model_selection, metrics, __version__\n",
    "from sklearn import tree as sk_tree\n",
    "from math import log2\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3c957-8259-42d2-9d48-b2979142b52a",
   "metadata": {},
   "source": [
    "## Creating the the different functions.\n",
    "\n",
    "### starting with the tree class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f606655-3fed-4eec-98a4-28c817bb71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple tree structure with maximum 2 children\n",
    "class Tree:\n",
    "    #Containing a value, either a lable or tuple with information about split. Then each child is a new tree object.\n",
    "    def __init__(self, value=None):\n",
    "        self.value = value\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.major_label = None\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb588e-5882-490a-8568-964ed07423cf",
   "metadata": {},
   "source": [
    "### Split labels\n",
    "Making a function to split a list of labels on its mean. The split function is too simple, because it would split it on the datapoint with the mean.\n",
    "I could sort the array, but I find it more simple and effective to retrieve the indexes instead and slice the points from the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20f245af-d101-4dba-9348-f1081e6ea2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_label(feature, labels):\n",
    "    #Finding feature mean\n",
    "    feature_mean = np.nanmean(feature)\n",
    "    #Splitting the feature on the mean\n",
    "    left_labels = labels[np.nonzero(feature < feature_mean)]\n",
    "    right_labels = labels[np.nonzero(feature >= feature_mean)]\n",
    "    #np.nonzero function finds the index in an array with a condition. Here the conditions are based on the mean.\n",
    "    return left_labels, right_labels, feature_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d8f850-8419-4bea-8ad3-845492dfd053",
   "metadata": {},
   "source": [
    "### Impurity and investigation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af6fd92b-c37e-4ee3-882a-3879c8695669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impurity(arr, impurity_measure = 'entropy'):\n",
    "    #Starting sum\n",
    "    entropy = 0\n",
    "    gini = 0\n",
    "    #Finding the counts for each possible label. Eihter one or two labels. \n",
    "    labels, counts = np.unique(arr, return_counts=True)\n",
    "    #Calculating the entropy and gini for the array\n",
    "    for count in counts:\n",
    "        prob = count/len(arr)\n",
    "        entropy -= prob*log2(prob)\n",
    "        gini += prob*(1-prob)\n",
    "\n",
    "    if impurity_measure == 'entropy':\n",
    "        return entropy\n",
    "    elif impurity_measure == 'gini':\n",
    "        return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f2b1d26-d624-4935-88c2-538d59b71ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_impurity(feature, labels, impurity_measure='entropy'):\n",
    "    #Getting the labels for the split\n",
    "    left_labels, right_labels, f_mean = split_label(feature, labels)\n",
    "    \n",
    "    #Finding the count of labels on each side\n",
    "    left_len = len(left_labels)/len(feature)\n",
    "    right_len = len(right_labels)/len(feature)\n",
    "\n",
    "    #Calculating the impurity measure for the feature and each split, and multiplying with the split ratio\n",
    "    impurity_left = impurity(left_labels, impurity_measure)*left_len\n",
    "    impurity_right = impurity(right_labels, impurity_measure)*right_len\n",
    "\n",
    "    #returning the conditional entropy\n",
    "    return impurity_left + impurity_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1194033f-f4f4-4e0b-99da-b8e0ea693c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigation_score(feature, labels, impurity_measure='entropy'):\n",
    "\n",
    "    #Getting the entropies\n",
    "    entropy_feature = impurity(labels, impurity_measure)\n",
    "    cond_entropy_feature = cond_impurity(feature, labels, impurity_measure)\n",
    "\n",
    "    #Returning the investigation score\n",
    "    return entropy_feature - cond_entropy_feature\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ee1c9-b929-455d-a2d6-74224314091f",
   "metadata": {},
   "source": [
    "### Finding the best feature to split on, by investigation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c8a4a07-63fd-408f-9237-df50026d30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_feature(data, labels, impurity_measure = 'entropy'):\n",
    "    #Making a dictionary to store the feature key and the inv_score as value. \n",
    "    best_i = {}\n",
    "    #Iterating through each feature\n",
    "    for feature in range(data.shape[1]):\n",
    "        best_i[feature] = investigation_score(data[:, feature], labels, impurity_measure)\n",
    "\n",
    "    #Finding best feature with max function, where the key is the values. \n",
    "    #print(best_i.values())\n",
    "    #if max(best_i.values()) > 0:\n",
    "    best_feature_index = max(best_i, key= best_i.get)\n",
    "    return best_feature_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef99aa0-f964-4807-bf66-c9368154eeec",
   "metadata": {},
   "source": [
    "### Splitting the data and labels into subarrays\n",
    "I chose to return a triple containing the left side, right side and value for the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61801dbf-9f79-4780-ab34-a3ae511f9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, labels, impurity_measure = 'entropy', feature_index='best', feature_mean='best'):\n",
    "    \n",
    "    #If we want to find best_feature or use a predetermined\n",
    "    if feature_index == 'best':\n",
    "        feature_index = find_best_feature(data, labels, impurity_measure)\n",
    "        best_feature_mean = 'best'\n",
    "\n",
    "    #Get the feature\n",
    "    best_feature = data[:, feature_index]\n",
    "\n",
    "    #Splitting the labels | Could have returned the labels in investigation_score to save compute, but this should be marginal.\n",
    "    left_labels, right_labels, best_feature_mean = split_label(best_feature, labels)  \n",
    "    \n",
    "    #Splitting the data based on the indexes of what points is lower or higher than mean, given specific feature\n",
    "    left_data = data[best_feature < best_feature_mean]\n",
    "    right_data = data[best_feature >= best_feature_mean]\n",
    "    \n",
    "    #Returning a 3-tuple consisting of the left side, the right side and information about the split (what feature, the mean)\n",
    "    #The latter will be stored in each branch when building the tree. \n",
    "    return (left_data, left_labels), (right_data, right_labels), (feature_index, best_feature_mean)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0cae93-4c02-41a4-86ec-b6b2629c5685",
   "metadata": {},
   "source": [
    "### Checking for identical features\n",
    "The approach is if there is only one unique value in every column, then the multi array has identical rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68c5f8f2-a3ee-4cb8-b950-e61c9a892610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identical_features(data, labels):\n",
    "    count = 0\n",
    "    for feature in range(data.shape[1]):\n",
    "        if len(np.unique(data[:,feature])) == 1:\n",
    "            count += 1\n",
    "    \n",
    "    if count == data.shape[1]:\n",
    "        uniques, counts = np.unique(labels, return_counts=True)\n",
    "        return uniques[np.argmax(counts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f482b-d36e-4c45-af7e-f9be017dabd4",
   "metadata": {},
   "source": [
    "## Implementing the ID3 function by using the prior built functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61eb97a8-1a75-45bc-a0f3-3ed7c568316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(data, labels, tree, impurity_measure = 'entropy'):\n",
    "    #Finding checking for identical features\n",
    "    identical = identical_features(data, labels)\n",
    "    \n",
    "    #If all data points have the same label:\n",
    "    if impurity(labels) == 0:\n",
    "        tree.value = labels[0]\n",
    "        return labels[0]\n",
    "\n",
    "    #Else if all data points have identical feature values\n",
    "    elif identical != None:\n",
    "        tree.value = identical\n",
    "        return\n",
    "\n",
    "\n",
    "    #Else\n",
    "    else:\n",
    "        #Extracting the information from the split\n",
    "        left, right, root = split_data(data, labels, impurity_measure)\n",
    "\n",
    "        if root != 0:\n",
    "            #Setting this root to indicate the split\n",
    "            tree.value = root\n",
    "\n",
    "            #Setting the majority label\n",
    "            lab, counts = np.unique(labels, return_counts=True)\n",
    "            maj_index = np.where(counts == max(counts))[0][0]\n",
    "            tree.majority_label = lab[maj_index]\n",
    "    \n",
    "            #Making left branch\n",
    "            new_left = Tree()\n",
    "            tree.left = new_left\n",
    "            id3(left[0], left[1], new_left, impurity_measure)\n",
    "    \n",
    "            #Making right branch\n",
    "            new_right = Tree()\n",
    "            tree.right = new_right \n",
    "            id3(right[0], right[1], new_right, impurity_measure)\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb721d-f322-4d49-88ee-0907d4dc661e",
   "metadata": {},
   "source": [
    "## Creating some functions to inspect the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b2b94a1-0c6a-44d6-b6f0-ed31e092fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tree(tree,count=0):\n",
    "    if tree != None:\n",
    "        counts = count\n",
    "        counts += 1\n",
    "        print(tree.value)\n",
    "    \n",
    "        search_tree(tree.left,counts)\n",
    "        search_tree(tree.right,counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8408223a-20e0-4cf5-97c8-adbe5838010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_nodes(tree):\n",
    "    if tree == None:\n",
    "        return 0\n",
    "\n",
    "    l = total_nodes(tree.left)\n",
    "    r = total_nodes(tree.right)\n",
    "\n",
    "    return 1 + l + r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059cb26c-d81d-4a74-a66b-10c7a1935090",
   "metadata": {},
   "source": [
    "## Prediction and accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31585334-147f-4159-a803-00a0041c0775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_point, tree):\n",
    "    if type(tree.value) == tuple:\n",
    "        feature, split_point = tree.value\n",
    "        if data_point[feature] < split_point:\n",
    "            return predict(data_point, tree.left)\n",
    "        else:\n",
    "            return predict(data_point, tree.right)\n",
    "    else:\n",
    "        return tree.value\n",
    "    #print(tree.value)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8021b256-a18f-48b2-ba30-a9170288fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_accuracy(data, labels, tree):\n",
    "    labels_len = len(labels)\n",
    "    if labels_len == 0:\n",
    "        return 0\n",
    "    count = 0\n",
    "    for counts, data_point in enumerate(data):\n",
    "        if predict(data_point, tree) == labels[counts]:\n",
    "            count += 1\n",
    "    return count/labels_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "620bb807-8adc-44bf-b06e-422ce1705769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_flat_label(data, labels, prediction=0):\n",
    "    labels_len = len(labels)\n",
    "    if labels_len == 0:\n",
    "        return 0\n",
    "    count = 0\n",
    "    for counts, data_points in enumerate(data):\n",
    "        if prediction == labels[counts]:\n",
    "            count += 1\n",
    "    return count/labels_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef7317-4367-4478-ad61-7f8277c6625f",
   "metadata": {},
   "source": [
    "## Pruning algorithm\n",
    "In essence a Depth first search. Since I implemented the tree structure to have a left and right child, I dont have a child list. But it works the same since when using a for loop on a list of children, you start with the first one and its first one etc. So I'm doing left side first, then calling right side when the left is searched. Instead of for loop im just using running it recusively as long as the child is a tree object. Then on each child im calculating if the accuracy is higher with a lable instead of a split, and if so, the new value is a label.\n",
    "\n",
    "If there is an empty array, then I'm not changing its branch. This is because the pruning data does not have the same data points as the training data. But when you calculate the accuracy and predictions with labels, they are all 0%. So the pruning data is not really suitable to determine wheter this split is necesarry or not. I have done some observations with different seeds and on average the accuracy declines when pruning these empty arrays. Hence im leaving the branches untouched.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe8949d9-f022-4fa1-be44-71f2b4cfd408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(data, labels, tree, impurity_measure = 'entropy'):\n",
    "    #Just want to do the pruning on a node that is splitting, not on a label node.\n",
    "    if type(tree.value) == tuple:\n",
    "        feature, mean = tree.value\n",
    "\n",
    "        #Incase there are empty branches. If the the data and labels are empty, then there is no reason to split it, so the datapoints can stay as they were.\n",
    "        #Since the accuracy is 0 with given data, but also 0 for either 0 or 1, so it would be unfair to choose one, because there is not enough data in pruning, to make a good decision.\n",
    "        if len(labels) == 0:\n",
    "            return\n",
    "        else:\n",
    "            left, right, values = split_data(data, labels, impurity_measure, feature_index = feature)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #If there is a left \n",
    "        if type(tree.left) == Tree:\n",
    "            prune(left[0], left[1], tree.left)\n",
    "        if type(tree.right) == Tree:\n",
    "            prune(right[0], right[1], tree.right)\n",
    "\n",
    "        #Accuracy of either splitting or giving hard label\n",
    "        for label in np.unique(labels):\n",
    "            if predict_flat_label(data, labels, prediction=tree.majority_label) > tree_accuracy(data, labels, tree):\n",
    "                #print('true')\n",
    "                #print(tree.value, left[1], right[1], predict_flat_label(data, labels, prediction=label), accuracy(data, labels, tree))\n",
    "                tree.value = tree.majority_label\n",
    "                tree.left, tree.right = None, None\n",
    "                #print(tree.value)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8765ca3-3a21-49f1-a2f0-68a3e7583f37",
   "metadata": {},
   "source": [
    "# The main learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46abd623-47e2-4eac-9b2d-84f6b9df45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the id3 algorithm to return a decision tree.\n",
    "def learn(X, y, impurity_measure='entropy', pruning=False, train_ratio=0.8):\n",
    "    #Making the root for the tree\n",
    "    tree = Tree()\n",
    "\n",
    "    #Checking whether the pruning is true\n",
    "    if pruning == True:\n",
    "        #Now we need to split the data\n",
    "        train_ratio = train_ratio\n",
    "        X_train, X_prune = np.split(X, [int(train_ratio*len(X))])\n",
    "        y_train, y_prune = np.split(y, [int(train_ratio*len(y))])\n",
    "\n",
    "        #Making the tree with training data\n",
    "        id3(X_train, y_train, tree, impurity_measure)\n",
    "        total_nodes(tree)\n",
    "\n",
    "        #Pruning the tree with the pruning data\n",
    "        prune(X_prune, y_prune, tree)\n",
    "        total_nodes(tree)\n",
    "\n",
    "        #Returning the pruned tree\n",
    "        return tree\n",
    "    \n",
    "    #Else if pruning is false | Just make the tree and return it.\n",
    "    else:\n",
    "        id3(X, y, tree, impurity_measure)\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a41d14-ea49-40e8-a4b9-c1a5305851b2",
   "metadata": {},
   "source": [
    "### read csv to numpy\n",
    "Nice to have if we want to load more datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9a9b874-9cc6-4e6e-b242-72ecbf8b54f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvs_numpy(name=''):\n",
    "    with open(name, 'r') as r:\n",
    "        reader = csv.reader(r)\n",
    "        data = list(reader)\n",
    "    \n",
    "    feature_names = data[0][:-1]\n",
    "    data_ar = np.array(data[1:], dtype=float)\n",
    "    targets = data_ar[:, -1]\n",
    "    data = data_ar[:, :-1]\n",
    "    return data, targets, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2522610c-45c7-4a14-9db2-fa72d2606ae9",
   "metadata": {},
   "source": [
    "# Testing withthe wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48f03310-43a1-4880-88d5-1a6ce72b65e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels, target_names = cvs_numpy('wine_dataset.csv')#\n",
    "seed = 333#332#333#521\n",
    "X_train, X_val_test, y_train, y_val_test = model_selection.train_test_split(data, labels, test_size=0.3, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2718a890-0210-40ae-973b-3418c26b2500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.13,  1.6 ,  3.34,  0.59,  9.2 ],\n",
       "        [ 0.1 ,  2.8 ,  3.6 ,  0.66, 10.2 ],\n",
       "        [ 0.32,  1.9 ,  3.2 ,  0.55,  9.5 ],\n",
       "        ...,\n",
       "        [ 0.44,  1.6 ,  3.38,  0.86,  9.9 ],\n",
       "        [ 0.36,  4.5 ,  3.4 ,  0.57, 10.4 ],\n",
       "        [ 0.34,  6.4 ,  2.99,  0.4 , 10.8 ]]),\n",
       " array([1., 1., 1., ..., 1., 0., 0.]),\n",
       " ['citric acid', 'residual sugar', 'pH', 'sulphates', 'alcohol'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels, target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ce9c04f-32e7-4f01-a07e-812d6967a4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = Tree()\n",
    "tree= learn(X_train, y_train, impurity_measure='entropy')\n",
    "tree_accuracy(X_train, y_train, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b7dd259-0c09-495b-9dab-a54ce7a6467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_ = Tree()\n",
    "tree_= learn(X_train, y_train, impurity_measure='gini', pruning=True, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdca0d5a-986e-4087-91df-dddde5c0329d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "757"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.left.left.value\n",
    "total_nodes(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49d65284-b147-46eb-899f-5a0eea945b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_accuracy(X_train, y_train, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a64d2b9-ecc0-4ac0-9b1f-324e5f569b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.865625"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_accuracy(X_val_test, y_val_test, tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bacfe6e5-7ddd-4e6e-9049-d2235475dbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(777, 0.8666666666666667)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_2 = Tree()\n",
    "tree_2 = learn(X_train, y_train, impurity_measure='gini')\n",
    "\n",
    "total_nodes(tree_2), tree_accuracy(X_val_test, y_val_test, tree_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8efe678-bc7f-4d13-b791-67f5741f707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prune(X_val_test, y_val_test, tree_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b98562f6-24d6-4fa8-94c5-eb7c7d04fba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "777"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_nodes(tree_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2faab63-d517-4297-b9fb-6959dd40500f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.865625, 757), (0.8666666666666667, 777))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tree_accuracy(X_val_test, y_val_test, tree), total_nodes(tree)), (tree_accuracy(X_val_test, y_val_test, tree_2), total_nodes(tree_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24878026-ad7b-45ff-89e6-36fa4a1743a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_flat_label(X_val_test, y_val_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89cf1b58-5b65-4975-a044-9053517f3241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4.406836461126005)\n",
      "(3, 0.6036129032258064)\n",
      "(3, 0.5007070707070707)\n",
      "(3, 0.4321588089330024)\n",
      "(3, 0.38327777777777783)\n",
      "(2, 3.161882352941176)\n",
      "0.0\n",
      "(1, 1.7875)\n",
      "0.0\n",
      "(1, 2.7866666666666666)\n",
      "(0, 0.22625)\n",
      "(0, 0.09)\n",
      "(0, 0.04666666666666667)\n",
      "(1, 2.25)\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "(0, 0.2971578947368421)\n",
      "(0, 0.20836734693877548)\n",
      "(0, 0.1305)\n",
      "(2, 3.267777777777778)\n",
      "(2, 3.11)\n",
      "(1, 2.6)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "(0, 0.1890909090909091)\n",
      "0.0\n",
      "(1, 2.0142857142857142)\n",
      "(1, 1.475)\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "(1, 2.029310344827586)\n",
      "(0, 0.25833333333333336)\n",
      "(0, 0.23374999999999999)\n",
      "(0, 0.21333333333333335)\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "(0, 0.26818181818181813)\n",
      "(3, 0.40599999999999997)\n",
      "0.0\n",
      "(1, 2.875)\n",
      "0.0\n",
      "1.0\n",
      "(3, 0.39999999999999997)\n",
      "(0, 0.2833333333333334)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "(3, 0.41173913043478266)\n",
      "0.0\n",
      "(4, 10.957142857142857)\n",
      "(1, 1.711111111111111)\n",
      "0.0\n",
      "(2, 3.2024999999999997)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "(0, 0.267219730941704)\n",
      "(0, 0.1395959595959596)\n",
      "(4, 10.057777777777776)\n",
      "1.0\n",
      "(0, 0.04933333333333333)\n",
      "1.0\n",
      "(1, 2.066666666666667)\n",
      "(0, 0.10999999999999999)\n",
      "0.0\n",
      "(1, 1.85)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "(4, 10.34753086419753)\n",
      "(1, 2.3181818181818183)\n",
      "(1, 1.8374999999999997)\n",
      "(2, 3.2290909090909086)\n",
      "(4, 9.633333333333335)\n",
      "0.0\n",
      "(0, 0.20000000000000004)\n",
      "1.0\n",
      "0.0\n",
      "(1, 1.64)\n",
      "(0, 0.21000000000000002)\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "(0, 0.21461538461538462)\n",
      "(1, 2.183333333333333)\n",
      "(3, 0.48666666666666664)\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "(0, 0.2022222222222222)\n",
      "(1, 4.075)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "(0, 0.21857142857142856)\n",
      "(2, 3.3939999999999997)\n",
      "(2, 3.344285714285714)\n",
      "(0, 0.20500000000000002)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "(1, 2.036363636363636)\n",
      "0.0\n",
      "(0, 0.25)\n",
      "0.0\n",
      "(0, 0.25333333333333335)\n",
      "1.0\n",
      "0.0\n",
      "(1, 1.8491935483870967)\n",
      "(1, 1.4554054054054055)\n",
      "(4, 10.635714285714286)\n",
      "0.0\n",
      "(1, 1.1823529411764704)\n",
      "(1, 1.0)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "(1, 1.6487179487179486)\n",
      "(4, 10.955)\n",
      "(0, 0.36375)\n",
      "(2, 3.1999999999999997)\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "(1, 1.7473684210526315)\n",
      "(0, 0.33777777777777773)\n",
      "(0, 0.2916666666666667)\n",
      "0.0\n",
      "(0, 0.31)\n",
      "1.0\n",
      "0.0\n",
      "(0, 0.43)\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "(4, 10.559)\n",
      "(4, 9.756666666666668)\n",
      "(1, 2.341176470588235)\n",
      "1.0\n",
      "(1, 2.75)\n",
      "1.0\n",
      "0.0\n",
      "(0, 0.36230769230769233)\n",
      "(2, 3.2975)\n",
      "(0, 0.30333333333333334)\n",
      "(0, 0.27666666666666667)\n",
      "1.0\n",
      "0.0\n",
      "(0, 0.33)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "(1, 2.06)\n",
      "1.0\n",
      "(0, 0.485)\n",
      "1.0\n",
      "0.0\n",
      "(0, 0.322)\n",
      "(2, 3.2183333333333337)\n",
      "0.0\n",
      "(2, 3.2714285714285714)\n",
      "0.0\n",
      "(0, 0.305)\n",
      "(1, 2.8000000000000003)\n",
      "(1, 2.1)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "(0, 0.2407172131147541)\n",
      "(0, 0.1069047619047619)\n",
      "(0, 0.03478260869565218)\n",
      "1.0\n",
      "(1, 2.1694915254237284)\n",
      "(2, 3.3893548387096772)\n",
      "(1, 1.8222222222222224)\n",
      "(1, 1.6909090909090907)\n",
      "(1, 1.5750000000000002)\n",
      "0.0\n",
      "(2, 3.3033333333333332)\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "(4, 10.026315789473681)\n",
      "(0, 0.19623188405797104)\n",
      "(2, 3.2875000000000005)\n",
      "(1, 2.3777777777777778)\n",
      "(4, 9.274999999999999)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "(0, 0.1911111111111111)\n",
      "(1, 2.3499999999999996)\n",
      "1.0\n",
      "(0, 0.15500000000000003)\n",
      "1.0\n",
      "(3, 0.5599999999999999)\n",
      "0.0\n",
      "1.0\n",
      "(1, 1.9833333333333334)\n",
      "(2, 3.410909090909091)\n",
      "(3, 0.5688888888888888)\n",
      "(3, 0.5375000000000001)\n",
      "0.0\n",
      "1.0\n",
      "(2, 3.3840000000000003)\n",
      "(0, 0.22)\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "(4, 10.430769230769231)\n",
      "1.0\n",
      "(2, 3.3625)\n",
      "0.0\n",
      "1.0\n",
      "(4, 10.56292372881356)\n",
      "(4, 9.779577464788732)\n",
      "(4, 9.402739726027397)\n",
      "(1, 2.1973684210526314)\n",
      "(1, 1.7894736842105263)\n",
      "(3, 0.5483333333333333)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "(2, 3.278285714285714)\n",
      "(1, 2.2190476190476187)\n",
      "(1, 1.8357142857142856)\n",
      "(3, 0.576)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "(4, 9.599999999999998)\n",
      "0.0\n",
      "(4, 9.639999999999999)\n",
      "(0, 0.38999999999999996)\n",
      "0.0\n",
      "(0, 0.435)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "(4, 9.564285714285715)\n",
      "1.0\n",
      "(1, 2.14)\n",
      "0.0\n",
      "1.0\n",
      "(4, 10.178260869565214)\n",
      "(1, 2.25)\n",
      "(4, 9.904761904761907)\n",
      "(0, 0.3093333333333333)\n",
      "1.0\n",
      "(3, 0.548)\n",
      "(0, 0.39999999999999997)\n",
      "1.0\n",
      "(0, 0.445)\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "(2, 3.171818181818182)\n",
      "1.0\n",
      "(1, 3.075)\n",
      "1.0\n",
      "0.0\n",
      "(1, 1.8297297297297295)\n",
      "(0, 0.3627272727272728)\n",
      "(2, 3.3400000000000003)\n",
      "(4, 10.385714285714286)\n",
      "(0, 0.31999999999999995)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "(1, 1.3777777777777775)\n",
      "0.0\n",
      "(2, 3.215)\n",
      "1.0\n",
      "(0, 0.46)\n",
      "1.0\n",
      "0.0\n",
      "(2, 3.2820000000000005)\n",
      "(1, 2.3125)\n",
      "1.0\n",
      "(1, 2.6666666666666665)\n",
      "0.0\n",
      "1.0\n",
      "(0, 0.3257142857142857)\n",
      "(0, 0.27)\n",
      "1.0\n",
      "0.0\n",
      "(0, 0.3675)\n",
      "0.0\n",
      "1.0\n",
      "(0, 0.3968085106382979)\n",
      "(0, 0.3229508196721311)\n",
      "(3, 0.5531034482758621)\n",
      "0.0\n",
      "(2, 3.237333333333334)\n",
      "0.0\n",
      "(0, 0.27666666666666667)\n",
      "0.0\n",
      "(0, 0.2975)\n",
      "1.0\n",
      "(0, 0.3033333333333333)\n",
      "0.0\n",
      "1.0\n",
      "(2, 3.189375)\n",
      "(3, 0.5499999999999999)\n",
      "0.0\n",
      "(1, 1.7600000000000002)\n",
      "(1, 1.5)\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "(4, 11.765)\n",
      "(1, 1.8250000000000002)\n",
      "(0, 0.3655555555555555)\n",
      "0.0\n",
      "(0, 0.38000000000000006)\n",
      "(4, 11.4)\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "(3, 0.5525)\n",
      "0.0\n",
      "(1, 2.2666666666666666)\n",
      "0.0\n",
      "1.0\n",
      "(1, 2.2954545454545454)\n",
      "(2, 3.2337499999999997)\n",
      "(1, 1.4928571428571424)\n",
      "0.0\n",
      "(2, 3.1)\n",
      "0.0\n",
      "1.0\n",
      "(0, 0.6377777777777778)\n",
      "1.0\n",
      "(2, 3.4033333333333338)\n",
      "0.0\n",
      "1.0\n",
      "(1, 2.8529411764705883)\n",
      "1.0\n",
      "(2, 3.1940000000000004)\n",
      "0.0\n",
      "(1, 3.7249999999999996)\n",
      "0.0\n",
      "1.0\n",
      "(2, 3.3019878603945374)\n",
      "(0, 0.4012426035502959)\n",
      "(0, 0.27144578313253015)\n",
      "(0, 0.17676470588235296)\n",
      "1.0\n",
      "(4, 10.0975)\n",
      "(4, 9.546666666666669)\n",
      "(4, 9.299999999999999)\n",
      "(2, 3.1566666666666663)\n",
      "1.0\n",
      "(0, 0.20333333333333337)\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "(1, 2.3)\n",
      "(2, 3.1887499999999998)\n",
      "0.0\n",
      "(0, 0.238)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "(4, 11.749999999999998)\n",
      "1.0\n",
      "(0, 0.236)\n",
      "0.0\n",
      "(0, 0.25666666666666665)\n",
      "1.0\n",
      "0.0\n",
      "(1, 2.0872448979591836)\n",
      "(1, 1.6054545454545457)\n",
      "(1, 1.346666666666667)\n",
      "0.0\n",
      "(4, 10.901960784313722)\n",
      "(1, 1.5250000000000001)\n",
      "1.0\n",
      "(0, 0.33499999999999996)\n",
      "0.0\n",
      "(0, 0.35)\n",
      "1.0\n",
      "0.0\n",
      "(3, 0.7555555555555555)\n",
      "0.0\n",
      "(4, 11.733333333333334)\n",
      "1.0\n",
      "0.0\n",
      "(1, 1.916)\n",
      "(4, 10.836111111111109)\n",
      "1.0\n",
      "(0, 0.35000000000000003)\n",
      "(0, 0.29000000000000004)\n",
      "0.0\n",
      "1.0\n",
      "(3, 0.8400000000000001)\n",
      "1.0\n",
      "0.0\n",
      "(2, 3.217692307692307)\n",
      "(0, 0.35333333333333333)\n",
      "0.0\n",
      "(0, 0.375)\n",
      "0.0\n",
      "1.0\n",
      "(4, 10.97)\n",
      "(4, 9.875)\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "(2, 3.202790697674418)\n",
      "(1, 3.0035714285714286)\n",
      "(3, 0.7539999999999999)\n",
      "(3, 0.6642857142857143)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "(4, 10.96551724137931)\n",
      "1.0\n",
      "(0, 0.343125)\n",
      "(0, 0.3111111111111111)\n",
      "(2, 3.2350000000000003)\n",
      "1.0\n",
      "0.0\n",
      "(2, 3.2659999999999996)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "(3, 0.7792441860465118)\n",
      "(0, 0.5251851851851852)\n",
      "(2, 3.1732352941176476)\n",
      "(1, 2.2062500000000003)\n",
      "(1, 1.7842105263157897)\n",
      "(3, 0.66625)\n",
      "(1, 1.45)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "(2, 3.0963636363636367)\n",
      "(4, 9.633333333333333)\n",
      "1.0\n",
      "(2, 3.0666666666666664)\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "(4, 10.376923076923076)\n",
      "1.0\n",
      "(3, 0.6699999999999999)\n",
      "(0, 0.4775)\n",
      "0.0\n",
      "(0, 0.48666666666666664)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "(1, 2.473611111111112)\n",
      "1.0\n",
      "(0, 0.4835714285714286)\n",
      "(1, 2.75)\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "(1, 2.5725)\n",
      "(1, 2.015625)\n",
      "(0, 0.5666666666666667)\n",
      "(1, 1.4666666666666668)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "(0, 0.2257943925233645)\n",
      "(0, 0.08389937106918238)\n",
      "1.0\n",
      "(2, 3.453157894736842)\n",
      "(3, 0.7200000000000001)\n",
      "(0, 0.1465217391304348)\n",
      "1.0\n",
      "(0, 0.19)\n",
      "(0, 0.16)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "(4, 11.478947368421052)\n",
      "1.0\n",
      "(3, 0.8157142857142856)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "(0, 0.36506172839506174)\n",
      "(1, 2.2193181818181817)\n",
      "(4, 10.465454545454547)\n",
      "(4, 9.660714285714286)\n",
      "1.0\n",
      "(2, 3.4327272727272717)\n",
      "1.0\n",
      "(3, 0.74)\n",
      "0.0\n",
      "1.0\n",
      "(1, 1.9)\n",
      "(4, 11.361538461538462)\n",
      "0.0\n",
      "(4, 12.049999999999999)\n",
      "(0, 0.314)\n",
      "(0, 0.27)\n",
      "1.0\n",
      "0.0\n",
      "(2, 3.4499999999999997)\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "(4, 11.242857142857142)\n",
      "(4, 10.877777777777778)\n",
      "(3, 0.7066666666666667)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "(2, 3.4579999999999997)\n",
      "(1, 2.1500000000000004)\n",
      "0.0\n",
      "(0, 0.34)\n",
      "1.0\n",
      "(2, 3.37)\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "(1, 2.7484848484848485)\n",
      "(2, 3.430000000000001)\n",
      "1.0\n",
      "(2, 3.5479999999999996)\n",
      "1.0\n",
      "(0, 0.25)\n",
      "0.0\n",
      "1.0\n",
      "(1, 3.15)\n",
      "(4, 10.911111111111111)\n",
      "1.0\n",
      "(1, 2.9)\n",
      "(0, 0.305)\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "(3, 0.66)\n",
      "1.0\n",
      "(0, 0.29000000000000004)\n",
      "(0, 0.275)\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "(2, 3.378243243243243)\n",
      "(4, 11.311904761904762)\n",
      "1.0\n",
      "(2, 3.3384210526315785)\n",
      "1.0\n",
      "(1, 2.3899999999999997)\n",
      "(0, 0.45199999999999996)\n",
      "(1, 1.8)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "(2, 3.433125)\n",
      "1.0\n",
      "(2, 3.494166666666666)\n",
      "1.0\n",
      "(0, 0.4225)\n",
      "1.0\n",
      "(0, 0.45999999999999996)\n",
      "1.0\n",
      "0.0\n",
      "(3, 0.5026453488372093)\n",
      "(2, 3.162794117647059)\n",
      "0.0\n",
      "(2, 3.2789304812834215)\n",
      "(4, 10.076521739130435)\n",
      "0.0\n",
      "(0, 0.3382978723404255)\n",
      "0.0\n",
      "(0, 0.42500000000000004)\n",
      "0.0\n",
      "(0, 0.558)\n",
      "(0, 0.4766666666666666)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "(3, 0.42986111111111114)\n",
      "(4, 10.586363636363636)\n",
      "0.0\n",
      "(0, 0.28214285714285714)\n",
      "(0, 0.21666666666666667)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "(3, 0.4694871794871794)\n",
      "0.0\n",
      "(1, 8.02608695652174)\n",
      "(0, 0.23538461538461541)\n",
      "(0, 0.10400000000000001)\n",
      "1.0\n",
      "(0, 0.185)\n",
      "1.0\n",
      "0.0\n",
      "(1, 5.85)\n",
      "0.0\n",
      "(0, 0.3125)\n",
      "1.0\n",
      "0.0\n",
      "(0, 0.389)\n",
      "0.0\n",
      "(0, 0.845)\n",
      "1.0\n",
      "0.0\n",
      "(3, 0.6142500000000001)\n",
      "(1, 9.41413612565445)\n",
      "(1, 6.895089285714286)\n",
      "(1, 5.591509433962265)\n",
      "(0, 0.36)\n",
      "(0, 0.2569230769230769)\n",
      "1.0\n",
      "0.0\n",
      "(1, 4.75)\n",
      "(0, 0.48666666666666664)\n",
      "0.0\n",
      "1.0\n",
      "(2, 3.0949999999999998)\n",
      "0.0\n",
      "(0, 0.5349999999999999)\n",
      "1.0\n",
      "0.0\n",
      "(1, 6.135)\n",
      "(0, 0.23214285714285715)\n",
      "(0, 0.13833333333333334)\n",
      "(0, 0.05333333333333334)\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "(0, 0.3291525423728814)\n",
      "(0, 0.25031250000000005)\n",
      "(3, 0.5614285714285714)\n",
      "(2, 3.3066666666666666)\n",
      "(0, 0.21000000000000002)\n",
      "(0, 0.195)\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "(0, 0.20375000000000001)\n",
      "(0, 0.15666666666666668)\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "(1, 8.024999999999999)\n",
      "0.0\n",
      "(0, 0.29571428571428576)\n",
      "(2, 3.22)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "(0, 0.4225925925925926)\n",
      "0.0\n",
      "(0, 0.5036363636363637)\n",
      "0.0\n",
      "(0, 0.67)\n",
      "0.0\n",
      "1.0\n",
      "(2, 3.1236708860759492)\n",
      "0.0\n",
      "(2, 3.2425714285714284)\n",
      "0.0\n",
      "(2, 3.3252941176470587)\n",
      "(4, 9.845454545454546)\n",
      "0.0\n",
      "(4, 10.7)\n",
      "0.0\n",
      "1.0\n",
      "(0, 0.26333333333333336)\n",
      "(0, 0.20666666666666667)\n",
      "1.0\n",
      "(1, 11.95)\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "(1, 9.158426966292135)\n",
      "(3, 0.760655737704918)\n",
      "(0, 0.3268421052631579)\n",
      "(2, 3.2833333333333328)\n",
      "0.0\n",
      "(2, 3.3669230769230767)\n",
      "(0, 0.21166666666666667)\n",
      "0.0\n",
      "(2, 3.3033333333333332)\n",
      "0.0\n",
      "1.0\n",
      "(4, 10.071428571428571)\n",
      "0.0\n",
      "1.0\n",
      "(1, 5.902941176470588)\n",
      "(2, 3.264545454545455)\n",
      "(0, 0.616)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "(1, 7.05)\n",
      "(0, 0.3825)\n",
      "(0, 0.3466666666666667)\n",
      "(1, 6.5)\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "(3, 0.888695652173913)\n",
      "1.0\n",
      "(3, 1.045)\n",
      "(0, 0.405)\n",
      "(0, 0.23500000000000001)\n",
      "0.0\n",
      "1.0\n",
      "(0, 0.575)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "(0, 0.3964285714285714)\n",
      "(2, 3.2199999999999998)\n",
      "(2, 3.1257142857142854)\n",
      "0.0\n",
      "(4, 9.4)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "search_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2be50c-943d-422d-8389-4cde572ae4ab",
   "metadata": {},
   "source": [
    "## Evaluating algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d67518-ae73-46d8-acd9-eac962fb19dd",
   "metadata": {},
   "source": [
    "Assess the performance of your algorithm using an appropriate performance\r\n",
    "measure. Which setting should you select for this data (entropy or Gini,\r\n",
    "pruning or no pruning)? What is your estimate for the performance of\r\n",
    "the selected model on unseen data points? Report how you arrived at the\r\n",
    "conclusi\n",
    "\n",
    "ons.\r\n",
    "Remember to use training, validation, and test sets properly. Note that in the\r\n",
    "model selection step you select one out of the four models (settings) based\r\n",
    "on performance on validation data, and in the model evaluation step you\r\n",
    "evaluate the selected model on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b527825-eead-4a04-bacf-89b8819af9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test = np.split(X_val_test, [int(len(X_val_test)/2)])\n",
    "y_val, y_test = np.split(y_val_test, [int(len(y_val_test)/2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ce29ebd-f392-4882-97fa-b2267a2b79ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_ratio(train_data, train_labels, val_data, val_labels, impurity_measure):\n",
    "    tree_prunefree = Tree()\n",
    "    tree_prunefree = learn(train_data, train_labels, impurity_measure=impurity_measure)\n",
    "    accuracy_prunefree = tree_accuracy(val_data, val_labels, tree_prunefree)\n",
    "    #print(f'Prune free accuracy: {accuracy_prunefree}')\n",
    "    ratios = {}\n",
    "    \n",
    "    for x in range(1,10):\n",
    "        tree = Tree()\n",
    "        tree = learn(train_data, train_labels, impurity_measure=impurity_measure, pruning=True, train_ratio=x/10)\n",
    "        accuracy_tree = tree_accuracy(val_data, val_labels, tree)\n",
    "        ratios[x/10] = accuracy_tree\n",
    "        #print(f'Testing training ratio: {x/10}, with impurity_measure: gini, accuracy: {accuracy_tree:.3f} | Difference in accuracy: {accuracy_tree- accuracy_prunefree:.5f}')\n",
    "    ratios[1] = accuracy_prunefree\n",
    "    best_ratio = max(ratios, key=ratios.get)\n",
    "\n",
    "    pruning = False\n",
    "    if best_ratio != 1:\n",
    "        pruning = True\n",
    "    \n",
    "    return [best_ratio, ratios[best_ratio], impurity_measure, pruning]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dbf3d8f3-cffe-46b6-9d8c-a2c9bc6582f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model uses impurity measure: entropy, with pruning: True, training ratio of: 0.7, and an accuracy of: 0.87292\n",
      "True\n",
      "The test accuracy on the best model is: 0.87500\n"
     ]
    }
   ],
   "source": [
    "testing = np.array([best_ratio(X_train, y_train, X_val, y_val, impurity_measure='entropy'),\n",
    "                    best_ratio(X_train, y_train, X_val, y_val, impurity_measure= 'gini')])\n",
    "train_ratio, accuracy, impurity_measure, pruning = testing[np.argmax(testing[:, 1])]\n",
    "print(f'The best model uses impurity measure: {impurity_measure}, with pruning: {pruning}, training ratio of: {train_ratio}, and an accuracy of: {accuracy.astype(float):.5f}')\n",
    "print((pruning))\n",
    "best_tree = learn(X_train, y_train, impurity_measure=impurity_measure, pruning=(pruning=='True'), train_ratio=train_ratio.astype(float))\n",
    "print(f'The test accuracy on the best model is: {tree_accuracy(X_test, y_test, best_tree):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24185562-9575-4f1e-9ab1-87b20046478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5fdb0d-6be6-43de-8f4d-94fe689cea0b",
   "metadata": {},
   "source": [
    "## SKLEARN test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5c0637c1-ddd3-4274-a033-8e35989458b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGFCAYAAABg2vAPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABMhElEQVR4nO3dd1QU1+M28GfpUkRsIFbsWLBgwYIgllji166xa0yMLYlGTSyJmqLGaBKTY9fEbqLGbixBA7EXUBQUBUQFRREFROks9/3D1/05uwvs4u4CzvM5Z8/xDnMLy7r77MydOwohhAARERHJlllRD4CIiIiKFsMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyZyFLjvFxMTgyZMnxh4LERERGUH58uVRrVq1PH9eYBiIiYmBu7s70tLSDDowIiIiMg1bW1uEh4fnGQgKDANPnjxBWloatm7dCnd3d4MPkIiIiIwnPDwcw4cPx5MnTwofBl5xd3dH8+bNDTY4IiIiKh44gZCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgG6K01f/58KBQK1WPjxo1FPSSVwMBAydhGjx5d1EMiIhmzKOoBEBEVlhACISEhuHr1KuLj46FUKlG2bFm4u7vDy8sL1tbWRT1EohKBYYCISpyMjAwsW7YMK1aswP3797XuY29vj+HDh2Pu3LmoVKmSScbl6+uL//77r9D1HR0dkZycbLgBEemIpwmIqES5efMmmjVrhlmzZuUZBADgxYsXWL16Ndzd3XHgwAETjpCo5GEYIKISIyIiAj4+Prh586Zku7W1NerVqwcPDw84ODhIfvbs2TP069cPe/bsMeVQiUoUniagt9b8+fMxf/78oh6GVr6+vhBCFPUwSpSsrCz0798fjx8/Vm2zsbHBd999h3HjxqlCgFKpxJ49ezB9+nTExMSoto0cORKNGzdGnTp1TDbmrVu3wtnZWef9LS0tjTgaorwxDBBRibBq1SqEhYWpyjY2Njh+/DjatWsn2c/c3BwDBw5E+/bt4ePjg8jISABAamoqZs6cid27d5tszO3atUONGjVM1h9RYfE0AREVe8+fP8eCBQsk27755huNIPC6SpUqYdOmTTAz+7+3uT179uDChQtGGydRScUwQETF3u7du5GQkKAqV6xYEVOmTCmwXps2bdCrVy/JtjVr1hh6eEQlHk8TUJGLiopCUFAQHj58iIyMDJQvXx4eHh5o2bKl5FtdUcvJycH58+cRGhqKxMRE2NnZwcXFBe3atUPVqlWLenhvtb1790rKY8aM0fn8+kcffYT9+/erygcOHIBSqYS5ublBx0hUookCBAcHCwAiODi4oF2J9LJnzx7RpEkTAUDrw8XFRSxevFhkZWUJIYTYsGGD5Ofz5s3Lt/158+ZJ9t+wYUO++/v4+Ej2v3PnjhBCiLS0NDF//nxRrly5PMfq5eUl/vvvP51/94CAAEn9UaNG6VxXbtLT04WNjY3k+QoICNCrvpWVlaR+YGCgUcaa12uIqCjp8jlefL52kWxkZWVh0KBB6NevH65evZrnfo8ePcIXX3yBdu3aSWaQm9Lt27fh6emJ+fPn4+nTp3nud/78eXTs2BErVqww4ejk4caNG8jIyFCVLS0t0bp1a53r29jYoGXLlpJtly9fNtj4iN4GDANkUjk5OejTpw927dql8bOyZcuiadOm8PDwgJOTk2r7pUuX0LNnT2RmZppyqLh//z58fX0RHh6u2lapUiU0b94cHh4esLe3l+yfm5uLyZMn459//jHpON92N27ckJRr1qyJUqVK6dVGw4YN823TmNLT0xEeHo7Tp0/jwoULiIyMxIsXL0zWP5EuOGeATGrhwoU4cuSIZFuHDh2wYMECtGvXDgqFAsDLD9YzZ85gzpw5OHXqFIKCgpCYmGjSsY4ePRr379+HpaUlJk6ciMmTJ6N27dqqn2dlZWHXrl2YMmUKnjx5oto+fvx4REVFFav5DiXZ62EMAKpXr653G+p11Ns0lt69eyM8PBzZ2dmS7WZmZvDw8ICfnx/Gjx9v0rUPiLThuxWZTGRkJL777jvJtnHjxiEwMBDt27dXBQHg5Zult7c3/vvvP4wdOxYAEB0dbdLx3r59G/b29jh27BiWLVsmCQIAYGVlhWHDhuHEiROSG+LcuXMHx44dM+lY8/P63RGN/TCG+Ph4SbkwkzWrVKmSb5vGcu3aNY0gALwMuyEhIfjpp59Qv359DBkyxORhl+h1DANkMsuXL5e8MbZs2RKrVq3K90NEoVBgzZo1aN68uSmGqGHVqlXo2LFjvvt4eHhg0qRJkm1///23MYclK+qH1O3s7PRuQ/2UTnE6TJ+bm4s///wTTZs2zXcODZExMQyQSSiVSmzevFmy7YcfftDpULq5uTl++OEHYw0tT02aNMHw4cN12nfIkCGScnBwsDGGJEvqH9z6zhfQVseYYcDKygrvvPMOfv75ZwQGBiIuLg5paWnIyMjAgwcPcPToUXz22WdwdHSU1IuNjUX37t1x7949o42NKC+cM0Amce3aNcmtWatXrw4fHx+d6/v5+aFq1aqIjY01wui0Gzp0qM77enh4wMLCAjk5OQBQrN7Q/f39i3oIbyQ9PV1StrKy0ruN10/jaGvTUKZOnYpdu3ahQoUKWn/u6uoKV1dXvPPOO5g7dy4mTJiAP/74Q/Xzhw8fYuTIkW90G2SiwmAYIJO4ePGipPz6ZEFdKBQKtGvXDn/++aehh5YnfS5fs7KyQpkyZVQTCZ89e2asYemtc+fORT2EN2JjYyMpZ2Vl6d2G+pUohTm6oIvevXvrvK+joyO2b98OOzs7rF+/XrX95MmTOHToEN59911jDJFIK54mIJNQv++8+qVeuihMnTdRsWJFvfZ//Vx2WlqaoYcjW+rn+wvzrV69jnqbRWn58uUaNzPatGlT0QyGZIthgEwiKSlJUi5Tpozebby+9oApGOvbI+lH/YM7NTVV7zbU5wgUpzBgbW2NTz/9VLLN398fSqWyiEZEcsQwQCahfpjWEOd9SR5cXFwkZfWjTLpQr+Ps7PxGYzK0Ll26SMrPnj3Dw4cPi2g0JEecM0AmoT5z+vnz53q3kZKSYqjhyMrx48dN1pcx5ie4u7tLyoWZnKleR73NoqZt7YTHjx9rrI9AZCwMA2QSZcuWlZQfPHigdxuFqUOa3zqNSQhh8DYbNGggKd++fRvp6el6nca5fv16vm0WNW13YHx1ZQqRKfA0AZlEo0aNJOXC3CiGN5eRpwYNGkiuKMjOzsaFCxd0rp+RkYFLly5JthXVIlZ5efTokca2vC5PJDIGhgEyiTZt2kjKZ86cyfcugOoSEhJw5swZQw+LSgAbGxuNoxtHjx7VuX5AQIDkcsRy5cqhXbt2BhufIaivK2BpaYlKlSoV0WhIjhgGyCQqVKiAtm3bqspZWVlYuXKlzvVXrFihdY13KpgQwmQPY+nbt6+kvGHDBp1fD2vWrJGUe/XqBQuL4nWGdO3atZJy+/btNdZXIDImhgEymQkTJkjKixYtQmhoaIH1QkJC8P333xtrWFQCDBgwAOXKlVOVHz9+jGXLlhVY7/z58zh48KBk20cffWTo4b2RlStX4ty5c5Jt/fv3L6LRkFwxDJDJvPfee2jWrJmqnJ6ejs6dOyMwMDDPOv/++y+6dOmCzMxMo90Vj4o/BwcHzJkzR7Jt7ty5+Z46erW0b25urmpbnz594OXlVWB/8+fP1+uOjC9evMCMGTP0vhxw5cqV+OSTTyTb3Nzc8OGHH+rVDtGbYhggk7GwsMDGjRslhz8fP36Mjh07omvXrvj111+xf/9+7N+/H7/88gs6d+6MTp064cmTJzA3Ny923+jItCZOnCi5CiAjIwOdO3fGTz/9JLlUValU4q+//oKXlxciIyNV221tbY12hCknJwdLly5FjRo18L///Q8bN25EZGSkJIi88vz5c+zduxc+Pj6YNGmSZHEhS0tLrFu3rlDrcBC9ieJ14ozeeh4eHti/fz/69OkjWSLW398/zxvqKBQKrFy5ElZWVli9erVqe3E770vGZW1tjd27d8Pb21t1D4iMjAxMmzYNs2fPhpubG6ysrHDnzh2NdSzMzc2xceNG1KtXz6hjzMrKwsGDB1WnJmxtbeHq6gpHR0eYmZkhMTERd+/e1bq6oKWlJbZs2YJOnToZdYxE2vDIAJlc165dcfLkSckpg7yUK1cOu3btwrhx4zSWlFVfyIjefvXr18d///2HunXrSrZnZmbi5s2buHbtmkYQcHBwwK5duzBw4EBTDhXAy3tUREVFITg4GJcuXcLt27e1BoGGDRviwoULGDx4sMnHSAQwDFARadGiBS5duoQ9e/Zg6NChqFOnDuzt7VWXVL06bRAdHa2aTKV+KWJh7m9AJV+DBg0QEhKChQsXwtXVNc/97OzsMG7cOISHh2tcjWBo9vb2WLVqFQYPHozq1avrVMfGxgZdu3bF7t27cfXqVZ3CMZGxKEQB1wNdvnwZnp6eCA4OLnYLdZC89O3bF/v27VOVT548CW9v76IbEBU5IQQuX76Ma9euIT4+HkqlEk5OTnB3d0ebNm2K7PK85ORkhIeHIyYmBvHx8UhNTUVubi4cHR3h5OSEevXqoUmTJlpXHiQyNF0+x3nSlUqEjIwMnDx5UlU2NzeHp6dnEY6IigOFQgFPT89i91ooU6YM2rRpo7HYFlFxxdMEVCJs2rQJiYmJqrKnpydsbW2LcERERG8PhgEyOX1Xqrt16xY+//xzyTZeh01EZDgMA2Ry/fv3x9KlS1WXh+VFCIG9e/eibdu2ktsXu7q6YujQocYeJhGRbHDOAJlcXFwcZsyYgZkzZ6JDhw7w8vKCu7s7nJycAACJiYm4evUqjhw5gvDwcEldMzMzbNmyhacIiIgMiGGAioxSqURAQAACAgJ02t/Kygrr1q2Dn5+fkUdGRCQvPE1AJlelShW963h7e+PkyZMYOXKkEUZERCRvPDJAJvfXX38hIiICx48fx/nz53Hr1i3Exsbi2bNnyMjIgL29PcqWLQs3Nzd4e3uje/fuOt1choiICodhgIpE3bp1UbduXUycOLGoh0JEJHs8TUBERCRzDANEREQyxzBAREQkcwwDREREMscwQEREJHMMA0RERDLHMECkB19fXygUCtXj7t27RT0kIqI3xnUGiIj08PDhQ4SFheHOnTtITk5Gbm4unJyc4OLiglatWqFSpUoG6yszMxM3b95EeHg4Hj9+jOfPn8POzg5OTk5wd3dHs2bNYGlpaZC+srOzERUVhbt37+L+/fuqRcBsbW3h6OiI2rVro1mzZihdurRB+nvl8ePHCAoKQmxsLJKTkyGEgKOjI1xcXNC8eXNUr17doP2RdgwDRET5SElJwcGDB/HPP/8gICAAsbGx+e5ft25djBs3DmPHjkWZMmX07u/KlSvYv38//v33X1y4cAFZWVl57mtjY4P//e9/+Pjjj9G+fXu9+9qxYwcCAwNx7tw5hIeH59sXACgUCnh7e+P999/H8OHDYW5urnefAJCVlYX169dj3bp1CAkJyXffmjVrYsyYMZg8eXKhnk/SkShAcHCwACCCg4ML2pXorefj4yMAqB537twp6iGREX366afC2tpa8jfX9VGpUiVx6NAhnfu6evWqqFOnTqH6AiBGjBghkpKS9Pr9ypUrV+j+mjRpIq5cuaLfEypefqa4u7vr3Z+Li4tezyf9H10+xzlngIgoD+fPn0dmZqbWn1WsWBGNGjVCixYttN586+HDh+jVqxd+++03nfqKi4tDZGSk1p+VKlUKbm5uaNmyJRo2bIhSpUpp7LNlyxb4+voiKSlJp/7yYmFhATc3NzRt2hStW7eGu7s7rK2tNfa7evUqfHx8cObMGZ3bvnjxIjp27Khxa3IAcHZ2RvPmzeHp6QlXV1eNnz969Ah9+vTBrl279PuFSCcMA0REOihVqhSGDRuGHTt24OHDh4iPj0doaCguXbqE2NhY3Lt3D1988YXkHL4QAuPGjdP5Nt2va9iwIRYtWoTz588jJSUF0dHRuHjxIsLCwpCcnIwDBw6gWbNmkjpXr15F//799erHxcUFY8aMwW+//YYbN24gLS0N0dHRuHLlCs6fP48bN27gxYsXCAgIQO/evSV1U1JSMHDgQCQnJxfYT3p6Ot577z2kpKRIto8dOxbh4eF49OgRgoODERQUhAcPHiA6OhpTpkyBmdn/fUzl5OTg/fffL/BUDRWCIQ4vEMkFTxPIS+vWrYWrq6v49ddfxbNnz3Sqc+7cOeHg4CB5nbi7u4ucnJx86x05ckQoFArRr18/ceHCBZ36yszMFEOHDtU4pL5t2zad6oeEhIjc3Fyd9n1l+fLlGv3NmTOnwHq//vqrRr01a9YUWG/fvn3CzMxMUm/y5Ml6jVnudPkcZxgg0gPDgLwcPHhQpKen611vx44dGh98AQEB+daJjIwUISEheveVnZ0tPDw8JH35+Pjo3Y4++vXrJ+mvTp06Bdbx9fWV1OncubPO/Y0ePVpSt3Llym8yfNnhnAEiojfw7rvvwsbGRu96gwYNQr169STbDh8+nG+d2rVro0mTJnr3ZWFhgVmzZkm2nT59Gs+fP9e7LV2NHj1aUo6KiirwSgT1eQKDBg3Sub/33ntPUn7w4AHS09N1rk8F46WFJpCZmYnQ0FBcv34diYmJSE1NhZWVFezt7VG5cmXUrFkT7u7usLDQ/8+hVCoRERGB8PBwxMXFISUlBVZWVihbtiyqVq0KLy8vODg4GOG3Au7cuYOQkBA8ePAAz58/R8WKFdG6dWs0atSowLpPnz7F2bNnERUVhfT0dJQrVw4NGzZEmzZtCn25kjZCCISEhCAkJATx8fGwsLCAq6srmjVrBnd3d4P1o6+MjAycO3cOsbGxSEhIgFKpRIUKFVCjRg20bdtW64QtfSQkJCAkJAS3b99GSkoKsrKyYGtrizJlyqB69eqoV6+e1klvZDi+vr64deuWqnzv3j2j9vU6pVKJ+/fvG+01Xrt2bUlZCIEnT55onfj3ytOnTyVlfdYPqFGjhsa2pKQkrRMpqZAMcXiBtLt165YYOXKkxvlDbY9SpUoJX19f8csvv4iMjIx823306JFYvny56NGjhyhdunS+7Zqbm4sOHTqIgwcP6nVuMCAgQNLOqFGjVD87cOCA8Pb2FgqFQmufnp6e4vTp01rbDQ8PF/379xcWFhZa6zo7O4t169bpPNYNGzZI6s+bN08IIYRSqRSrVq0SNWrUyPO5adSokdi5c6fOz4kQb36aICAgQHTr1k3Y2Njk+1oYNGiQuH79ul5tCyHEn3/+Kdq1a5fn3+b1R6VKlcSIESPEiRMn9O6HCjZz5kzJ8921a1ej9ZWRkaHx9z179qzR+rty5YpGfy9evMi3jvpljHv37tW5v8uXL0vqmpmZFer0jVxxzkARWrFihbCysirwDVnbIzY2Ns927969K8zNzQvVbt++fUVKSopO49cWBnJzc8WkSZN06svCwkJs3bpV0ua2bdtEqVKldKr/0Ucf6RQItIWBFy9eiG7duun1vOj6xlLYMJCQkKDXmF694X399dc6tf/8+XO923/16NSpk059kH6GDx8ueZ6HDRtmtL6ioqI0/q6RkZFG62/VqlWSvtzd3Qus06VLF0mdmTNn6tzfihUrJHU9PT3fZPiyo8vnOE8TGMH27dsxadIkje1WVlaoUaMGHB0dAby8LCcmJkavc1/Z2dlQKpWSbWZmZqhSpQrKlCkDW1tbpKam4t69exqX8OzduxePHz9GYGBgoU5JTJs2DStWrFCVHR0dUa1aNVhaWuLOnTuS65tfXQLk7u6O5s2bY+fOnRgxYgRyc3NVz4WbmxtKly6Nhw8f4v79+5K+1qxZgwYNGuCTTz7Ra4xCCAwePBhHjx5VbbO3t0f16tVhaWmJe/fuaVyHvXfvXvTp0wcHDhyAlZWVXv3pIiIiAt27d0d0dLTGzypVqgRnZ2eYm5sjLi4ODx8+VP0sNzcX8+bNw4MHD7BmzZp8++jfvz/++ecfje1OTk6oWrUqbG1tkZ6ejqSkJMTGxkII8ea/GOUpNzcXJ0+elGxTn0NgSIGBgZJyqVKlULVqVaP0lZqaiiVLlki2jRkzpsB6Q4cOhb+/v6q8bt06TJs2DeXLl8+3XlpaGn7++WfJtnHjxukxYtKJIRIF/Z/MzExRoUIFSYpt166dOHbsmMjMzNTYX6lUioiICLFq1SrRrVs3YWZmlu+RgcjISAFAtGzZUixYsEBcunRJpKWlaeyXm5srQkNDxZQpUzSOUHz55ZcF/h7qRwZeP9zu5eUljh8/LrlUKicnR+zbt0+4uLhI6nXo0EFEREQIW1tbAUBUrVpVbNy4UTx//lzS3+XLl0WrVq0kdR0cHERiYmK+41Q/MuDm5qb6d+3atcW+fftEVlaW5Pn+77//hJeXl8Y3KV2eF32PDDx79kzUrl1bUsfZ2Vn88MMP4v79+xr7R0REiIkTJ2pcSpXfJVh79uyR7Gtubi6mTp0qbt26pXX/1NRUcfr0aTFnzhxRp04dHhkwgsOHD2u8vgqzWp+uWrduLemrd+/eRuknKipK4/9O48aNCzy1KcTLqx48PT01vuHn93/o0aNHws/PT+M9paDLNEmKpwmKwJEjRyQvXG9vb71euNHR0Vo/3F9JTk4WQUFBeo3pwoULokyZMqoxlS5dusBrptXDwKvHyJEj8/19QkNDhaWlpaROgwYNBADRvHlzkZCQkGfdlJQUjQ/OFStW5DtO9TDwegDL7xymUqnUuD7bwsJChIaG5tufvmFgyJAhkv19fX3FkydP8q0jhBCHDh2SPI/29vZ5BqPBgwdL+li7dm2B7b+Sm5srbty4ofP++pg3b55epyve5PFqrkhxkJWVpXGpX/PmzY3W359//qnxfBw4cKBQbcXExAh/f3/V49ixY2L37t1iyZIl4t1339X4v+3h4SHi4uJ0bj82NlZjyWVra2sxZMgQsXr1anHw4EFx6NAhsX79ejF69GhhZ2cn2dfHx0ckJycX6neTM4aBIrBs2TLJi/ePP/4o6iEJIYRYs2aNZFzr1q3Ld39tYaBZs2Zaj26oGzt2rEZdBwcHcffu3QLrbt68WVKve/fu+e6vLQyULVs239DxSlZWlmjYsKGk7tixY/Oto08YuHbtmmQiX926dQucZPW6pUuXSvr69ttvte7XtGlT1T52dnbF5luTXMPAF198oTG+48ePG6Wv+/fvi/Lly0v68vb2LnR7P//8s07Pt7Ozs1i4cKFORwTUPXv2TEyaNEmvez7Url1brFq1SiiVykL/bnLGdQaKQFpamqRs6Nt9FtawYcMkl+ydPn1a7za+/fZbnc6p9+3bV2Pb+PHjdbqUqHfv3lAoFKry5cuX9RskgNmzZxd4HhIALC0t8cMPP0i2/fHHH3jx4oXefWqzdOlSybn5pUuXws7OTuf6kydPlvweO3fu1Lrf6685W1tbg16aSfrZu3evxmvqgw8+QKdOnQzeV0ZGBgYMGIAnT56ottna2mL9+vUG7+t1VatWxbx58zBx4sRCXQJbunRpLF++HKdOndJYTlmbWrVq4fPPP8fIkSMlSxOTYXECoYFVrlxZUt6+fTt69OhRRKP5P3Z2dqhYsaJqglpwcLBe9UuXLo3u3bvrtG/jxo01tg0ePFjnfqpXr467d+8CAOLj45GZmanzm46FhQVGjhyp074A0K1bN1SuXBkPHjwA8PKD9fz58+jcubPObWgjhMDff/+tKleoUEHv14G1tTX8/PxUISAsLAyJiYkoW7asZL/KlSsjIiICwMv1BY4fP/7G4zeEkSNHFuq2uoVRs2ZNk/STn6CgIAwfPlwSABs2bIhly5YZvC8hBEaPHo3z589Ltq9cuRJ169Y1eH+vi42NxcSJE/HFF19g9uzZmDFjhl4BNCoqCtOnT8eBAwd0msh6+/ZtjBs3DnPmzMGPP/6IESNGvMnwKS+GOLxA/+f+/fsa19APGDBAXL582eB9ZWdniyNHjohPP/1U+Pn5iWrVqokyZcrodOmhs7Nzvm2rnybo2LGjzuNKTU2V1LW0tNTr0HXLli0l9ePj4/PcV/00QdOmTXXu5xX1uQN5HY4XQvfTBKGhoXqd7sjLjBkzJO1oW7/h+++/l+xjb28vFi9erNPcBDKM8PBwjYnDLi4uIioqyij9ffzxxxr/p6dPn27wfrKzs0VCQoI4ffq0WLhwoahVq5ZGv3369JFM0s3PwYMHNeYBeHl5iU2bNonbt2+LtLQ0kZqaKqKiosTGjRs1JkYCELNmzTL47/m245yBIjJ58mStH8A1a9YUH330kdiyZYuIiIgodPtKpVKsXbtWODs7F/ocq7W1db59qIeBQYMG6TVGfYKHOvUP3PzmGqiHgREjRujVlxCaH6ZjxozReWx5hQFtk7oM8di/f79GX8nJyaJy5coa+1pYWIgOHTqIuXPniiNHjhR4ZQYVTnR0tMbzX7ZsWXHt2jWj9Dd79myNv/W4ceOM0pe6rKwsrXNBpk2bVmDdc+fOaVzZtHTp0gLrLVmyRKO/zZs3G+LXkQ2GgSKSlZWlMYtc28PZ2VkMHjxY7Ny5M98rCNTbVr9JSGEf+clvBUJdvF63evXqetXVZ5KeehiYOnWqXn0JIcT69eslbfTt2/eNx6a+SIqhHps2bdLa37Vr1/JdbRGAUCgUwsPDQ0yfPl1cunRJ7+eJNMXExGg876VLlzba8/vtt99q/F2HDx9u8ol18+fPl4zBzMxM3L59O8/9lUqlqF+/vqTO559/rnN/6kfIypcvr/N7JnECYZGxtLTE9u3bcejQIXh7e0smxL0uPj4eO3bswKBBg1C9enX89NNPGgsKqZs6dSr27Nkj2WZnZ4du3brhyy+/xOrVq7F7924cOnQI/v7+koezs7PBfsfiSp8JennVMcQNXnS5v3thvFq0SV3jxo0RGhqK7777Ls97DgghcO3aNSxduhQtW7ZE27ZtcfbsWaOMUw4ePnyITp06qea3AC8XuDpy5AhatGhh8P6WLl2Kr776SrJt4MCB2Lhxo8kn1s2ePVsyITg3NxcbNmzIc/8jR47g5s2bqrKjo6PG75Kfr776SjIZ+8mTJ9i7d6+eo6b8cAKhEfXs2RM9e/ZETEwMjh8/jpMnT+LMmTOIiorS2DchIQHTpk3DkSNHcPDgQa13Srt+/TpWrVol2fbZZ59h7ty5qlUN85NXKHmbpKamvnEdQ9zYydbWVlLu2LEjZs+e/cbtNmzYMM+f2dvbY86cOZg1axYuXLiAwMBAnDx5EufPn9caTs6dO4cOHTpgxYoV+Oijj954bOqio6O1rrpoDDVr1jTpJML4+Hj4+fkhMjJStc3W1haHDh1C27ZtDd7fL7/8ghkzZki29e7dG9u2bSuSq0csLS3Rp08f/PLLL6pt+QXL11ceBAA/Pz/Y29vr3J+DgwM6duyI/fv3q7adPHkSQ4cO1WPUlB+GAROoVq0a3n//fbz//vsAgMePH+PkyZP4+++/sXv3bsk30ePHj+OLL76Q/Cd7ZceOHZJvhmPGjMGPP/6o8zjUl+F9G71+mVVh65QpU+aNx6F+aaO1tbXJZvibmZmhTZs2aNOmDWbNmoXc3FzcuHEDJ06cwN69e3Hy5EnVLG6lUomJEyeiRYsW8PT0NOg4Nm/ejK+//tqgbeZl3rx5mD9/vkn6SkhIQKdOnSTfdG1sbLB//374+PgYvL+VK1diypQpkm09e/bEzp07YWlpafD+dKV+58K4uLg891UPhYUJbrVq1ZKU1ZcwpzfD0wRFoGLFihgwYAA2bNiA+/fva1wqs3r1aq2Hqs+cOSMp67Nuf2RkJDIzMws34BLk2rVrete5evWqpGyIb5jqbby69K8omJmZoVGjRvj0008RGBiIoKAgyS1hc3Nz9QqVcvb06VN07twZ169fV22ztrbGvn37jBL21q5di8mTJ0u2de3aFbt37zbKfTTeRH7BRP29pzAhRr1OXqfMqHAYBopY6dKl8dtvv0nOv2VlZeHChQsa+z569EhSrl+/vs79HD9+vPCDLEGuX7+Ox48f67y/thvKeHl5vfE4WrVqJTndEB0djTt37rxxu4bQvHlzrF27VrJN/TkgTUlJSejSpYskcFpZWWH37t145513DN7fhg0bMH78eMm1+J06dcK+ffsKtdiPoam/nl1cXPLcV/1I2at1PfShfiSgQoUKerdBeWMYKAYsLS01PoASEhI09hNqC3RkZWXp1L4QQnK3wbdZTk4OtmzZovP+R48elbwx2draonXr1m88DgsLC3Tt2lWyTf3Oa0XJ29tbUtb2entT8+fPh3h5xZLRH8Y+RfDs2TN07doVV65cUW2ztLTEzp070bNnT4P3t2XLFnzwwQeS//M+Pj44cOAASpUqZfD+9JWbm4uDBw9KtjVt2jTP/V8/EgUAAQEBen2zVyqVCAgIkGxTP21Ab4ZhoJhQfzNWX2UOeHm729fp+m3uxx9/lBzWfNstXLhQp7kD2dnZ+PzzzyXbhgwZYpAJhAAwc+ZMSXn16tXF5hu4Lq83eun58+fo1q0bgoKCVNssLCzwxx9/oHfv3gbv788//8SYMWMkH5bt27fH33//rTExtaisXLlSMnkS0L4M+StdunSRlO/fv4/Nmzfr3N/vv/+uMSdBPWzTm2EYMLAvv/wSGzZs0Ov8/JkzZ/Dff/+pyubm5lpTtvrSrl9++WWBs+e3b9+OWbNm6TyWt0FiYiL69OmT73OTm5uLMWPGSEKShYUFPv30U4ONo0WLFhg0aJCqnJ2djT59+uDw4cN6tZOcnIwlS5ZoffNMSUnBe++9p/W0Un4WLlyoMVbSlJaWhp49e0qW/TU3N8e2bdvQv39/g/e3Z88ejBgxQnKJcdu2bXHkyJFCXTabn48//lgScHS1fv16jQmNvr6+aNOmTZ512rdvr/FN/uOPP8a5c+cK7O+///7T6K9hw4Zo1aqVzmOmgvFqAgMLCwvDggULMG3aNPTq1Qu9e/dGq1attF77/eDBA2zcuBELFiyQ/Ofv16+f1jUBRowYgYULFyInJwfAy4lv3t7e+Pnnn9GhQwfJpYMhISFYsmQJtm/fDgBwdnZGTk4Onj59auhfuVipUaMG7t69izNnzqBZs2ZYsmQJevTooZp8JITA6dOn8cUXX2i8Ec2YMUPrfRXexPr163H9+nVV6EhKSsK7776L3r17Y8KECWjfvr3Gt73c3FxERkbi/Pnz2LdvH/755x+kpaVh0aJFGu3n5uZix44d2LFjBxo2bIh+/fqha9euaNq0qcalW7m5ubhw4QIWLVqkcYh3woQJBv293xa9evXCqVOnJNtGjx6NsmXLFmoeTn6TDE+cOIH33ntP9f8bAMqVK4dp06Zp3INAFwVdbnnw4EEsX74cLVq0wIABA9CpUyc0bNhQ62mIhIQE/PPPP1i9erXGTc4cHBw0LnlWZ2Fhge+//x4DBw5UbXvx4gV8fHwwdepUjB8/Hm5ubpI6t2/fxsqVK/Hrr79KnhMAWLx4MW9aZGiGWLmI/k/v3r21rv7m5OQk6tevL1q3bi08PT1FpUqVtO5XuXJl8ejRozzbnz59utZ6ZcuWFZ6enqJZs2Yaa6RbWloKf39/Ub169bd+BcK5c+eKHj16SLY5ODiIxo0bi2bNmomyZctqff66dOmi0+1Y9RnbK/fu3RONGzfW2q+lpaWoVauWaNmypfD09BS1atUStra2WvddtGiRRttJSUl5rjZYtWpV4eHhIby8vETjxo2Fvb291n0/+OCDAn8HudL2fL3JIz+GvuVzQbd1Vn8/ACDMzc1FtWrVVK8bDw8P4eLikmcfpUuXFmfPntX5+Zw5c2aebbm6ugpPT0/RvHnzPN8fgfzvHULa6fI5ziMDJpKUlFTgdf4tW7bE7t27810p8Pvvv0dcXJzqG/8riYmJSExM1NjfwcEB27ZtKxZ3sTMFhUKBHTt2YMCAATh27BiAl+d8Q0ND86zzv//9D3/++afRZmhXq1YN58+fxyeffIINGzZIzgVnZ2fj9u3buH37dr5tWFpawtXVVec+hRCIjY1FbGxsnvuYm5tj2rRpWo84kDwplUrExMQgJiamwH27d++O5cuX63Up7qJFi+Dq6oqZM2dq3O49Li4u37UK7O3t8eOPP2LcuHE690e643EWA1u/fj02bdqE9957L89lYV+nUCjg7e2NzZs348KFC6hatWq++786X7lhwwaNRT9eZ2Njg9GjR+P69evo1auX3r9HSWZvb4/Dhw9j5cqVkks21TVo0ADbt2/H/v37jT5D+9V95sPDw/Hhhx/qtDS0g4MDevbsieXLlyMuLk7rrZnLlCmDkJAQLFiwAL6+vjqdVy5dujRGjRqFK1eu8HCrjB08eBDff/89unTpotMKpsDL0xYffPABTp06hcOHDxdqTY6PP/4YN27cwOeff57v5YivuLq6Yvbs2QgPD2cQMCKFEPnfUPry5cvw9PREcHAwmjdvbqpxvTXi4uJw8+ZN3L17F0lJSUhPT4eNjQ1Kly6NOnXqoEmTJoWeyS2EQGhoKIKCgpCQkAClUgknJyfUq1cPXl5exWbmsTFt3LgRY8aMUZXVV6ITQuDKlSsICQlBfHw8LCwsUKlSJTRv3hwNGjQoghH/n/DwcISFheHp06dITEyEhYUFHBwc4Orqivr166NWrVqwsNDv4J1SqcTNmzcRFRWFBw8eICUlBUqlEvb29ihfvjwaNmyIhg0bFunKdVT8CCEQHR2NqKgoxMTE4NmzZ0hPT4etrS0cHR1RsWJFNGnSJN9wXVjR0dG4cuUKHj9+jGfPngGAqk9PT0+NyxJJf7p8jvM0gZG5urrqdXhXHwqFAh4eHvDw8DBK+28DhUKB5s2bF8sg6+7uDnd3d4O2aW5urvrAJ9KVQqFArVq1iuTafVPfV4K04/FBIiIimWMYICIikjmGASIiIpljGCAiIpI5hgEiIiKZYxggIiKSOYYBIiIimeM6A1SijR49GqNHjy7qYRARlWg8MkBERCRzDANEREQyxzBAREQkcwwDREREMscwQEREJHMMA0RERDLHMGBACoVC9eA9uOWpRo0akteBtkdycnJRD5OIikBycnKB7w9F9dnBdQaIqMgplUpcunQJYWFhSEhIAABUqFABjRo1QsuWLWFubm6QfmJiYhAWFoaYmBgkJyfDzMwMTk5OqFy5Mlq3bo1y5coZpB8ynMzMTNy6dQv37t3DgwcP8Pz5c2RmZsLe3h5lypRBvXr10KRJE9ja2hql/5ycHAQHB+PmzZt4/PgxMjMzYWdnh0qVKqF27dpo3LgxrK2tjdK3KTEMEBVj2dnZCA0NRVBQkOoRFhaG7Oxs1T4+Pj4IDAw0SH+PHj2S9BUUFIT4+HjJPgEBAfD19TVIf8+ePcP333+PdevW4enTp1r3KVeuHD744APMmjULjo6OerX/5MkT7N27F8ePH0dAQIAqaOSlWbNmGD9+PEaMGIFSpUrp1VdRMuXfzdivSaVSiQ0bNuDMmTM4f/48IiMjoVQq861jbm6Od955Bx9++CH69OlTqH7VhYaG4qeffsLu3bvx/PnzPPezsrJCy5Yt8e6772LmzJkG6btIiAIEBwcLACI4OLigXWUPgOpRvXr1oh4OFYHq1atLXgf+/v4aj+zs7ALbmTBhgmjZsqWwtraWtKft4ePj80Zj9vf3F7179xaVK1cusC8AIiAg4I36e+Xs2bPC1dVVpz4BCFdXV3H27Fmd2+/Xr58wNzfXuf3XH3Xr1hXnzp0zyO9pLKb+u5nqNfn8+fNC/c1ePXx9fUV0dHSh+09NTRUTJ04UZmZmevVrbW1dYNvZ2dla3xOM/dmhy+c4jwwQGVHnzp0LVW/VqlUGHkneTp8+jf3795usPwA4e/YsunTpgrS0NMl2W1tbuLm5QQiBO3fuID09XfWzuLg4dOnSBf7+/mjTpk2BfZw5c0brN0qFQgEXFxdUrFgR5ubmePDggca36IiICPj4+GD//v3o1q1bIX9L4zL1382Ur0ltrK2tUbVqVZQuXRoWFhZISkrCnTt3kJOTI9kvMDAQ7du3x7///ot69erp1Ud8fDx69OiBy5cva/zM0dERLi4uKFOmDF68eIEHDx7oPf/HwsKi0O8JxsYJhEQliEKhgJ2dncn6s7e3N3ibT58+xYABAyRBoGzZsvjtt9+QmJiIsLAwXL9+HYmJiVi3bh2cnJxU+6WmpqJ///55nlLIi6OjIz766CPs378fT58+RVxcHEJCQhAcHIxHjx4hPDwcH374IRQKhapOVlYW+vbti5s3b775L21ixvi75cVYr8kaNWpgwoQJ2Lp1KyIjI5GamorIyEgEBwfjwoULiIiIwIsXL3Dw4EF06NBBUjcuLg6DBg2SnLooSEpKCrp27SoJAjY2Npg+fTqCgoKQlJSEmzdv4vz58wgLC0NSUhJiYmKwadMmDBgwoOTPGzDE4QV6CTxNIHvqpwkKC4BQKBSiVq1aYtCgQWLx4sXixIkTIikpScybN8+gpwletWdvby+8vb3FlClTxJYtW8SNGzeEUqk0+OHmKVOmSNqrUKGCCA8Pz3P/GzduiPLly0vqfPbZZwX24+zsLOrWrSs2btwo0tLSdBrb3r17hYWFhaSvLl266Py7mZKp/26mek1mZ2eLq1ev6l1vxowZGr/zunXrdK4/atQoSd3GjRuLO3fu6Fz/6dOneo/5FWN/dujyOc4wYEAMA2SoMPDqTVYbQ4eBmzdvqj5AtDHkh8rdu3c1zjnv3LmzwHo7duzQOD977969fOvs2bNH5OTk6D3GxYsXa/zO+nwomIop/25CmPY1WRhKpVK0aNGiUEHu8OHDknr169d/ow93fRWHMMDTBETFkJ+fH8qUKWOSvurVqwd3d3eYmRn/7WDDhg3IzMxUlZs2bYqBAwcWWG/QoEFo2rSpqpyZmYmNGzfmW6dv376FuiTx008/RenSpSXbDh8+rHc7xmbKvxtg2tdkYZiZmWHkyJGSbdevXy+wnhACH3/8saqsUCjw22+/oWzZsgYfY3EmuwmESqUSERERCA8PR1xcHFJSUmBlZYWyZcuiatWq8PLygoODQ1EP02QyMjJw7tw5xMbGIiEhAUqlEhUqVECNGjXQtm3bkn8ejIqVvXv3SsofffSRznXHjRuHiRMnqsp79uzB3LlzDTa2V6ytrdGmTRscO3ZMte3evXsG74cMr3bt2pJyQZeSAsCxY8dw+/ZtVbl79+5o27atwcdW3Jk8DMyaNQvff/+9qjxp0iQsX75c73YeP36MKlWqqCaIWFtbIy4uTmuai4+Px19//YXDhw/j9OnTSElJybNdc3NztGvXDjNmzEDPnj0lE4oMaf78+fj6669V5Q0bNmD06NE61x89ejQ2bdqkKut7DXFgYCAWL16MwMBAZGRkaN2nVKlS6NWrF+bNm4cGDRro3DaRNnfv3sW1a9ck2/SZqa++79WrV3Hv3j1Ur17dION73euTFgFw1cgS4vWjTgB0OpKxZs0aSXnUqFGGHFKJYfLTBO+//76kvH37do0/oC62bNkimSnap08frUHg3r17qFy5MiZPnozDhw/nGwSAl0cOTp48iV69eqF///75LjZREj158gTdu3dHx44dcfTo0TyDAACkp6dj586daNy4Mb755hsTjpLeRuqXa1WuXFmvpVfd3NxQuXLlfNs0lPv370vKFSpUMEo/ZFjnz5+XlFu0aJHv/tnZ2Th69KhkW3G99M/YTB4G6tSpA29vb1U5KSlJ49ChLjZs2CApjx07Vut+2dnZGtcam5mZoVq1avDw8ICXlxcaN26scY4QeHlIs3v37hrXsZZUERERaN26tcaLHwAqVaqEpk2bwtPTE5UqVZL8LDc3F/PmzdPrkC6Ruhs3bkjKjRo10ruNhg0b5tumIaSkpGiEDH2vVyfTe/jwoca3/DFjxuRb59q1a5IvRFWrVlV9qczKysLevXvRv39/1KtXD3Z2dnB0dETt2rXRu3dvLF++XKfTECVFkUwgVD868Pvvv+tV/+LFi5KJIdWqVUOnTp3yrdOyZUssWLAAly5dwosXL3Dv3j1cvXoV586dw7Vr15CcnIzQ0FBMmTIFVlZWqnpnzpyRHM4vqVJSUtCzZ09ER0ertjk7O+OHH37A/fv3ERcXhytXriAoKAhxcXGIiIjAxIkTJZOT1q5di7Vr1xbF8OktEB4eLikX5vC+eh31Ng1h27ZtkjUQzM3N0aNHD4P3Q4Zz+fJldOzYUXI655133sGAAQPyrXfhwgVJ+dWcg4sXL8LDwwP9+vXDnj17EBERgbS0NKSkpOD27ds4cOAAPv74Y9SsWRPz5s17K74wFskEwoEDB+KTTz5RHYI/ceIEYmJiUK1aNZ3qq4eHMWPG5DmjtkKFCggKCoKnp2e+bSoUCjRq1Ag///wzhgwZgnfeeUf1wvr1118xY8YMrUcPSorx48cjKipKVfb19cVff/2V541Z6tSpgxUrVqBHjx7o27ev6pTMtGnTMHDgQI1zqoZgrPkZ2ry8modMSX2Vv6pVq+rdRpUqVfJt800lJyfj22+/lWzr3bs3b2BUxCIiIhATE6MqK5VKpKSkIDIyEidOnEBgYCByc3NVP/fz88OuXbsKfE+JjIyUlEuXLo09e/Zg0KBBBd4PAQBevHiBb775BmfOnMFff/1VrK+2KEiRHBmws7PD4MGDVeXc3NwCLxN6JT09HX/++aeqrFAo8j0U5OjoWGAQUNeqVSssXrxYVU5JScHOnTv1aqM4CQ0NlTxndevWxaFDh3R6g+vZsycWLVqkKr948QIrVqwwyjjp7fbixQtJuTCr1qmvrKfe5puaMGECHj58qCpbWlpiwYIFBu2D9Ldy5Up06dJF9ejWrRsGDRqEOXPm4N9//1UFATc3N6xatQr+/v46XRWWlJQkKd++fRvDhg1TBYEyZcpgwoQJ2LJlC/7++29s2bIFEyZM0PgydOLECQwZMqREf8kosnUG1M/xb9y4Uacncs+ePXj27Jmq3KlTJ6PMJh42bJjkGuXTp08bvA9TWbp0qeS5Xbp0qV5vxJMnT0b58uVV5ZIcjKjoqH9wF+augOp1DBkGli1bJgnNADBv3jzUr1/fYH2Q8TRo0ABff/01Ro8erfPaC+pXiYSFhanmEPTo0QORkZFYuXIlhg8fjh49emD48OFYuXIlIiIiNE4dHT16FMuWLTPEr1IkimydAS8vLzRo0EA1AejOnTsIDAxEx44d862nfopAff6BodjZ2aFixYqqbwnBwcFG6cfYhBD4+++/VeUKFSroff7T2toafn5+qhAQFhaGxMREgy/K4e/vb9D2qHh5/aZDACRzc3Slvu6FepuFdfDgQUyfPl2yrVOnTiX7lrQyc+PGDYwcORKfffYZFi9erNNnQ15hsm3btti3bx8sLS21/rx8+fLYt28ffH19cfbsWdX2xYsXY8KECbCxsSncL1GEinTRoTFjxmDGjBmq8u+//55vGLh79y4CAgJUZScnJ/Tt21fn/nJycnD8+HEcPXoUoaGhiIqKQkpKCp4/f17g+aGSOmv0+vXrkpu6tGjRolCrsr1+9EUIgfDwcLRr184gY3xFrpf0yIX6G2RWVpbebahfhlyYowvqTp8+jcGDB0veA+rXr48dO3YU6v8KGd6yZcsk37qzsrKQlJSEGzdu4MSJE/j9999VX9yePHmCsWPH4vLlywWuYaPtQ1uhUGDdunV5BoFXLC0tsW7dOjRq1Eh15DU+Ph67d+/GsGHD9PwNi16RLkc8cuRIyRO+e/fufNcBUD+VMHToUJ0SWG5uLtatW4cqVaqge/fu+OWXX/Dvv/8iJiYGycnJOk0UKamLjqgvx3nkyBEoFAq9H0uWLJG0o+9d44jUz/cX5lu9ep03vTtfUFAQevbsKWnXzc0Nx48f56TBYszKygrOzs7o2LEjvvvuO0RGRuLDDz+U7LNixYoCw4C2eQUdOnTQeZG1Bg0aaHyBff0La0lSpGGgYsWK6Nmzp6qcnp6OP/74Q+u+QgjJinuAbqcIsrOzMXDgQIwbN+6NZh4XZmGk4sBYH9olNRxR0VH/4E5NTdW7DfXDum8SBq5du4Z33nlH8gWkSpUqOHHihMbiRlS82dnZYe3atRqruM6ZMyffL5jaXj9+fn569a0eBi5evKhX/eKiyO9NMHbsWOzbt09V/v3337UubvPvv//i7t27qnLTpk3RvHnzAtufOnUq9uzZI9lmZ2cHb29vtGjRAlWqVEGFChVgbW2tcT5y+PDhBr90ydSM9aH9+mU8RLpwcXGRlNVX+dOFeh1nZ+dCjeXGjRvo3LkzEhMTJeM7ceIE3NzcCtUmFb2ffvoJu3btUgXNlJQU7Nq1K89F6dRfk4D+C0ypTzB9/PixXvWLiyIPA927d0elSpVU53suXryIGzduaBymKczEwevXr2PVqlWSbZ999hnmzp0LR0fHAuub8rp3Y7G1tZWUO3bsiNmzZ79xu+orwRnC8ePHDd5mXjg/wfTc3d0l5cLc/Ee9jnqburh16xY6deokmQdUoUIFnDhxAnXr1tW7PSo+nJyc0LlzZ+zfv1+17ezZs3mGAW3vY7p8NuS3/+sBsyQp8jBgbm6OUaNGSW5e9Pvvv2Pp0qWq8rNnzyRLFltbW+s0QWPHjh2Sb7BjxozBjz/+qPPY1K9BNaQ3DRqvr5CWn9cvCQRePnfF9YOwS5cuJuurJF8PXFKpB/ywsDC921CfA6PvDbSioqLg5+eHR48eqbaVK1cOx48f58243hLqdy6Mi4vLc19tYSC/+7Voo76/+hewkqJI5wy8ov4tf+vWrZLlHf/44w/JBJ+8bkqk7syZM5LyJ598ovOYIiMjjTpPQH3io76TqXQ9FFWzZk1JOSIiQq9+iAxF/bTe/fv3Jaf+CnLnzh08ePBAsq1Zs2Y614+OjkbHjh0lHw5OTk7w9/eHh4eHzu1QyZLfVQH16tXTmDeg76lh9f3Vv4CVFMUiDNSpUwft27dXlePj43Ho0CFVubBrC7ye/gHNczv5MfYha/VDS/q8AJVKpc53a2vVqpVkxmx0dDTu3Lmjc19EhlKjRg00btxYsk3bTbPyor6vh4eHznc9vHfvHvz8/CRzDhwdHXHs2DG9AgUVf+rvb9rmBbxiZWWlse7KpUuX9OpPfcJgSV2kqliEAUBzRcJXAeD69euSP061atV0PsytfihY1+uahRBGX3JX/U1Mn1uxHjhwQOdbK1tYWKBr166SbT///LPOfZmSEMJkDyoa6uuC6HPjK/V9+/Xrp1O92NhYdOzYUTLfwMHBAUePHkXLli117p+Kv9TUVI3Fy5o2bZpvHfWbGe3fv1/no8KZmZmSCfAACrxpXnFVbMLAwIEDJd9gjxw5gkePHmkcFdBnqUn1W/GePHlSp3o//vijxrlJQ1O/z7a/v79OE08yMjIwd+5cvfpSX0Vt9erVOj8XRIY0ZswYycqDV65cwa5duwqst3PnToSEhKjKVlZWGpeRaRMXFwc/Pz/Jt0V7e3scOXIEXl5eeo2dir958+ZJvigpFAr06dMn3zq9evWS3DTryZMn+PXXX3Xq79dff5VMRLW0tET//v31G3QxUWzCgPrNi3JycvD7779j69atqm0F3ZRI3eunHgDgyy+/LPDa5u3bt2PWrFk691FY5cuXR+vWrVXljIwMTJ06Nd86GRkZGDZsmN4Tr1q0aIFBgwapytnZ2ejTpw8OHz6sVzvJyclYsmQJNm/erFc9oldq1KiB8ePHS7ZNmjQJN2/ezLPOzZs3MWnSJMm2iRMnFnhPksePH6NTp06Su3Xa2dnh8OHDBl898xVfX1/JYl2+vr5G6edtNmrUKL3nNimVSnzzzTcaE8RHjhwJV1fXfOva2Nho3Ixq7ty5BZ4q9vf31/hiNnLkSJ3vvlvcFPnVBK97//33sX79elX522+/lczU9PPz0/kcIQCMGDECCxcuVE1GvHr1Kry9vfHzzz+jQ4cOkhn9ISEhWLJkCbZv3w7g5fXLOTk5Rl1pb+LEiZL7aW/evBmZmZlYtGiR5FrnjIwMHD58GPPmzUNYWBgUCgXc3NwQHR2tc1/r16/H9evXVUc8kpKS8O6776J3796YMGEC2rdvrzELNjc3F5GRkTh//jz27duHf/75B2lpaZK7GJJxPHz4MM+jU+p/96SkpDzfuJycnHS6a+eZM2d0nsQaHByc5/3bPT09C7y99VdffYUdO3ao5skkJCSgXbt2WLJkCYYNG6Za7yMzMxNbt27FjBkzJFf2ODs7Y86cOfn2kZaWhs6dO2uEjE8//RSZmZl6zwkqVaqU0QLEmzDl381Ur8nNmzdj69ataN++PQYMGAAfHx+4u7trnQj44MEDHDp0CCtXrsS1a9ckP6tUqZLGyql5GT58ONatW4dTp04BePme27NnT8yYMQOTJ0+WzDt49OgRVqxYgR9++EFy6rlatWqSq+JKHFGA4OBgAUAEBwcXtKtBuLu7CwBaH9u3b9e7venTp2ttq2zZssLT01M0a9ZMVKhQQfIzS0tL4e/vL6pXry7ZXpDX961evXqB++fm5ooOHTpoHZ+bm5to1aqVcHd3FzY2NpKfzZ8/X4waNUqyLSAgoMD+7t27Jxo3bqy1P0tLS1GrVi3RsmVL4enpKWrVqiVsbW217rto0SIdnnl50vc1k5cNGzbk+f9An4ePj0+hxl3Yhy6vQyGEOHnypChVqpRGfVtbW9GoUSPRsGFDra8/W1tbcerUqQLbv3PnjkF+H33+PwshhI+PT6Ge/8Iy5d/NVK9JbXWsrKyEm5ubaNq0qfDy8hKNGjUS5cqVy7OPypUri1u3bun1XD58+FDUqVNHoy2FQiFq164tWrVqJWrXri0UCoXGPk5OTiIoKEiv/vL6nXV9relDl8/xYhcGlixZovWP6+TkJNLT0/VuLycnRwwdOlTnF6qDg4M4cOCAEEL/N/bC/EHj4+NFs2bNdBqbQqEQX3/9tRBCFCoMCCFEamqqGDt2rDAzMyvUf2RLS0uxadMmnfqSI4aBAJ1/x1OnTgkXFxed23ZxcRGnT5/Wqe2iCgOtW7eW1Ovbt6/Oz0dhyCUM6PMYPny4iI+PL9Tz+fDhwzy/oOX1cHd3FxEREYXqT9vvXFRhoNjMGXhF/eZFrwwZMqRQt4U0NzfHtm3bsGHDBo3FKF5nY2OD0aNH4/r16+jVq5fe/RRWxYoVcerUKXz11VcoXbp0nvt5e3vj1KlTek8eVGdra4v169cjPDwcH374oU7LuTo4OKBnz55Yvnw54uLiMHLkyDcaAxHwck5PeHg4Pv/883wPUTs5OWHGjBlGuVOmIaWmpuLKlSuSbV988UURjabkOnfuHObNm4cOHTrAzs5OpzqVK1fGlClTEBISgi1btqBixYqF6tvFxQWBgYHYtGkTmjRpku++7u7uWL16Na5evYo6deoUqr/iRPH/U0meLl++DE9PTwQHB+t0L4DiTAiB0NBQBAUFISEhAUqlEk5OTqhXrx68vLyKfOWo7OxsnDt3Djdv3sTTp09hbm6OqlWrol27dkadlBIeHo6wsDA8ffoUiYmJsLCwgIODA1xdXVG/fn3UqlULFhbFanpJsVWjRg3JJWwF/Pei/y8nJwcXL15EWFgYnjx5AuDlJNtGjRqhVatWJeL1d+TIEck16/3798dff/1VhCMq+ZRKJSIjI3H79m3ExsYiJSUFWVlZsLOzg6OjI1xdXdG0adN81xJ4E3fu3MGlS5cQGxuL9PR0ODk5oWLFimjdurVB35Nfn79WvXp1vRbj0oUun+PF/3+YASkUCnh4eBTb1cYsLS3RoUMHdOjQwaT9uru7F2qNdyJDsbCwQNu2bdG2bduiHkqhvT5hzsLCAgsXLizC0bwdzM3NUb9+/SJbyMfNzU02N64qdqcJiN4mr19m9urB2z+/nV5f7Gbs2LG86RFpSE5O1vqeUBwwDBARvaHHjx+r1v+wtbXF/Pnzi3ZARHpiGCAiekPHjx9XzQ+ZOnWq0c5hExmLrOYMEBnbtm3bClwERv0uaVTyDR06FEOHDi3qYVAxZ29vr3HvBHWlSpUy0WikGAaIDKg4X/pGREXLwsJC5xvtmRpPExAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyRzDABERkcwxDBAREckcwwAREZHMMQwQERHJHMMAERGRzDEMEBERyZyFrjuGh4cbcxxERERkBLp8fhcYBsqXLw9bW1sMHz7cIIMiIiIi07K1tUX58uXz/LlCCCEKaiQmJgZPnjwx6MCIiIjINMqXL49q1arl+XOdwgARERG9vTiBkIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjmGAaIiIhkjmGAiIhI5hgGiIiIZI5hgIiISOYYBoiIiGSOYYCIiEjm/h/qu9Ydnd/SZwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = sk_tree.DecisionTreeClassifier(criterion=\"gini\",)\n",
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = sk_tree.DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clfs.append(clf)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "sk_tree.plot_tree(clf)\n",
    "tree = learn(X_train, y_train, impurity_measure='gini')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6790c4c6-e5af-4228-873e-81ce68d790e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.00022166834226988383, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0002647866812299341, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.00027660751521341344, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0002813358488068051, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0002918057303350296, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.000294421237123401, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0002970290249572888, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0002980297425366092, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.00036822492098987703, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.00038299502106472626, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.00040214477211796256, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.00040214477211796256, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.00040620684052319444, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0004095918975275544, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.00041245617653124335, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.00041482837346491135, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.00041890080428954424, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0004220037732102076, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.00042612323194970894, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.00042651718254935433, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.00043643618679468834, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.000444978947346183, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.00044682752457551384, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.00044682752457551384, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0004915102770330652, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0004964750273061263, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.000543963942961495, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0005590985818867853, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0005704181164793796, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0005709462814020458, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0005744925315970891, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0005792172232081803, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0005852254304174878, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0005957700327673518, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0005957700327673518, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0005957700327673518, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0005957700327673518, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0005957700327673518, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0005957700327673518, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0006379804601901399, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0006580550816475748, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0006622213056529413, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0006702412868632708, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0006702412868632708, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0006702412868632708, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0006853945681314842, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0006931555188927842, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.000695065038228577, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0006954699646692869, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0007095396120551538, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.000714924039320822, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.000714924039320822, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.000714924039320822, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.000714924039320822, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.000714924039320822, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0007447125409591898, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0007447125409591898, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0007462466554636286, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0007659900421294525, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0007659900421294525, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0007745010425975575, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0007819481680071493, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0007819481680071493, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0007943600436898022, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0007943600436898023, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0008266841722401434, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0008356255005048572, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0008410871050833204, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0008572209542421281, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0008589365157729784, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0008694600791447739, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0008830162985658968, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0009634429558233711, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.000992950054612253, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0010284125565626905, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0010705750180011223, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0010723860589812331, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0010947274352100089, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0011498862705296986, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0011506872632877987, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0012484600032159193, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0013891907993784666, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0014644247747112211, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0015012179129365588, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.001532109038811449, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0015743767103771269, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0015758117366696442, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0016174752020833073, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0016348309802069656, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0021133242388743454, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.002177420873856508, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.002554364015490021, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0026384578094503473, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0027515771030608783, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.002930597907084523, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0038188166344535184, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.003957410407497149, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.004328527765807291, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.007993158225052883, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.009561115242038606, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.011050753305136565, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.01139885529176024, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.022413962970336918, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.02602958805398499, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0678135537603009, random_state=0),\n",
       " DecisionTreeClassifier(ccp_alpha=0.1465109345792096, random_state=0)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "40ee4333-bf94-4d5a-84e6-290d3d04ce08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.5075960679177838, 0.45, 0.5145833333333333\n",
      "Accuracy sklearn: 0.45\n",
      "Accuracy my implementation: 0.8645833333333334\n"
     ]
    }
   ],
   "source": [
    "train_pred = clf.predict(X_train)\n",
    "val_pred = clf.predict(X_val)\n",
    "test_pred = clf.predict(X_test)\n",
    "\n",
    "train_acc = len(train_pred[train_pred == y_train])/len(y_train)\n",
    "val_acc = len(val_pred[val_pred == y_val])/len(y_val)\n",
    "test_acc =len(test_pred[test_pred == y_test])/len(y_test)\n",
    "print(f'train: {train_acc}, {val_acc}, {test_acc}')\n",
    "print(\"Accuracy sklearn:\",metrics.accuracy_score(y_val, val_pred))\n",
    "val_pred = []\n",
    "for x in X_test:\n",
    "    val_pred.append(predict(x, tree))\n",
    "\n",
    "print(\"Accuracy my implementation:\",metrics.accuracy_score(y_test, val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cceac23e-730e-4c30-abcf-3980a4506398",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = [clf.score(X_train, y_train) for clf in clfs]\n",
    "test_scores = [clf.score(X_test, y_test) for clf in clfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0e713f08-993c-4061-a962-65a48298c5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8958333333333334"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da3090-deb5-43d6-ae54-f5130b46e0d5",
   "metadata": {},
   "source": [
    "## Testing with different dataset\n",
    "found on kaggle: https://www.kaggle.com/datasets/abineshkumark/carsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fcdf727-76be-40df-9dab-c8b735b58b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>cubicinches</th>\n",
       "      <th>hp</th>\n",
       "      <th>weightlbs</th>\n",
       "      <th>time-to-60</th>\n",
       "      <th>year</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350</td>\n",
       "      <td>165</td>\n",
       "      <td>4209</td>\n",
       "      <td>12</td>\n",
       "      <td>1972</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.9</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>71</td>\n",
       "      <td>1925</td>\n",
       "      <td>14</td>\n",
       "      <td>1980</td>\n",
       "      <td>Europe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>11</td>\n",
       "      <td>1971</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400</td>\n",
       "      <td>150</td>\n",
       "      <td>3761</td>\n",
       "      <td>10</td>\n",
       "      <td>1971</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.5</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>63</td>\n",
       "      <td>2051</td>\n",
       "      <td>17</td>\n",
       "      <td>1978</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>305</td>\n",
       "      <td>130</td>\n",
       "      <td>3840</td>\n",
       "      <td>15</td>\n",
       "      <td>1980</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>36.1</td>\n",
       "      <td>4</td>\n",
       "      <td>91</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16</td>\n",
       "      <td>1979</td>\n",
       "      <td>Japan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232</td>\n",
       "      <td>112</td>\n",
       "      <td>2835</td>\n",
       "      <td>15</td>\n",
       "      <td>1983</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232</td>\n",
       "      <td>100</td>\n",
       "      <td>3288</td>\n",
       "      <td>16</td>\n",
       "      <td>1972</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>105</td>\n",
       "      <td>3353</td>\n",
       "      <td>15</td>\n",
       "      <td>1977</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg   cylinders  cubicinches   hp  weightlbs   time-to-60   year  \\\n",
       "0    14.0           8          350  165       4209           12   1972   \n",
       "1    31.9           4           89   71       1925           14   1980   \n",
       "2    17.0           8          302  140       3449           11   1971   \n",
       "3    15.0           8          400  150       3761           10   1971   \n",
       "4    30.5           4           98   63       2051           17   1978   \n",
       "..    ...         ...          ...  ...        ...          ...    ...   \n",
       "256  17.0           8          305  130       3840           15   1980   \n",
       "257  36.1           4           91   60       1800           16   1979   \n",
       "258  22.0           6          232  112       2835           15   1983   \n",
       "259  18.0           6          232  100       3288           16   1972   \n",
       "260  22.0           6          250  105       3353           15   1977   \n",
       "\n",
       "        brand  \n",
       "0         US.  \n",
       "1     Europe.  \n",
       "2         US.  \n",
       "3         US.  \n",
       "4         US.  \n",
       "..        ...  \n",
       "256       US.  \n",
       "257    Japan.  \n",
       "258       US.  \n",
       "259       US.  \n",
       "260       US.  \n",
       "\n",
       "[261 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cars.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35972c7e-9fa5-4ebb-a0a7-e8ae4b3b49f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.0, 8, '350', ..., 12, 1972, ' US.'],\n",
       "       [31.9, 4, '89', ..., 14, 1980, ' Europe.'],\n",
       "       [17.0, 8, '302', ..., 11, 1971, ' US.'],\n",
       "       ...,\n",
       "       [22.0, 6, '232', ..., 15, 1983, ' US.'],\n",
       "       [18.0, 6, '232', ..., 16, 1972, ' US.'],\n",
       "       [22.0, 6, '250', ..., 15, 1977, ' US.']], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.to_numpy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca574c68-ac59-4459-bfd4-750a8ce81218",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[:, -1]\n",
    "data = data[:, :-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd02e3d4-ed07-4127-b1a7-c26e4e4a01b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.0, 8, '350', ..., '4209', 12, 1972],\n",
       "       [31.9, 4, '89', ..., '1925', 14, 1980],\n",
       "       [17.0, 8, '302', ..., '3449', 11, 1971],\n",
       "       ...,\n",
       "       [22.0, 6, '232', ..., '2835', 15, 1983],\n",
       "       [18.0, 6, '232', ..., '3288', 16, 1972],\n",
       "       [22.0, 6, '250', ..., '3353', 15, 1977]], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e4df006-c6a7-43db-8000-9c44c9e9b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[:, 2] == ' '] = 0 \n",
    "for x in data[:,2]:\n",
    "    x = int(x)\n",
    "\n",
    "data[:, 2] = data[:, 2].astype(int)\n",
    "\n",
    "data[data[:, 4] == ' '] = 0 \n",
    "for x in data[:,4]:\n",
    "    x = int(x)\n",
    "\n",
    "data[:, 4] = data[:, 4].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8e8026-0046-45e4-9bf0-5dd52941968b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b40dc-94dd-4587-9a6a-e893df1c32fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15be11a2-74f4-45ed-bc4e-0d80fd8c3624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([' Europe.', ' Japan.', ' US.'], dtype=object),\n",
       " array([ 48,  51, 162], dtype=int64))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9bacae7-2bac-45f1-bd62-8e1855389526",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_3 = Tree()\n",
    "tree_3 = learn(data, labels, impurity_measure='entropy', pruning='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2aa28f47-3f35-4df8-96a3-ea178ba76415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4013498193719667"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impurity(labels[:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7e68722-5f29-448b-8bbb-54d155f2ca1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9961685823754789"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_accuracy(data, labels, tree_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07985698-4b1f-4777-becd-37b74947cc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' US.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(data[0], tree_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ed55b4a-d308-459b-847d-fb6a42eb0880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' US.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76db938-4c06-4f99-9e29-ac95ec6cfd29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
