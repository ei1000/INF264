{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce77f734-cae6-4ec2-aace-df325a9cd059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import neighbors, datasets, model_selection, metrics, __version__\n",
    "from math import log2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3c957-8259-42d2-9d48-b2979142b52a",
   "metadata": {},
   "source": [
    "## Creating the the different functions.\n",
    "\n",
    "### starting with the tree class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f606655-3fed-4eec-98a4-28c817bb71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple tree structure with maximum 2 children\n",
    "class Tree:\n",
    "    #Containing a value, either a lable or tuple with information about split. Then each child is a new tree object.\n",
    "    def __init__(self, value=None):\n",
    "        self.value = value\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb588e-5882-490a-8568-964ed07423cf",
   "metadata": {},
   "source": [
    "### Split labels\n",
    "Making a function to split a list of labels on its mean. The split function is too simple, because it would split it on the datapoint with the mean.\n",
    "I could sort the array, but I find it more simple and effective to retrieve the indexes instead and slice the points from the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20f245af-d101-4dba-9348-f1081e6ea2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_label(feature, labels):\n",
    "    #Finding feature mean\n",
    "    feature_mean = np.nanmean(feature)\n",
    "    #Splitting the feature on the mean\n",
    "    left_labels = labels[np.nonzero(feature < feature_mean)]\n",
    "    right_labels = labels[np.nonzero(feature >= feature_mean)]\n",
    "    #np.nonzero function finds the index in an array with a condition. Here the conditions are based on the mean.\n",
    "    return left_labels, right_labels, feature_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d8f850-8419-4bea-8ad3-845492dfd053",
   "metadata": {},
   "source": [
    "### Impurity and investigation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af6fd92b-c37e-4ee3-882a-3879c8695669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impurity(arr, impurity_measure = 'entropy'):\n",
    "    #Starting sum\n",
    "    entropy = 0\n",
    "    gini = 0\n",
    "    #Finding the counts for each possible label. Eihter one or two labels. \n",
    "    labels, counts = np.unique(arr, return_counts=True)\n",
    "    #Calculating the entropy and gini for the array\n",
    "    for count in counts:\n",
    "        prob = count/len(arr)\n",
    "        entropy -= prob*log2(prob)\n",
    "        gini += prob*(1-prob)\n",
    "\n",
    "    if impurity_measure == 'entropy':\n",
    "        return entropy\n",
    "    elif impurity_measure == 'gini':\n",
    "        return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f2b1d26-d624-4935-88c2-538d59b71ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_impurity(feature, labels, impurity_measure='entropy'):\n",
    "    #Getting the labels for the split\n",
    "    left_labels, right_labels, f_mean = split_label(feature, labels)\n",
    "    \n",
    "    #Finding the count of labels on each side\n",
    "    left_len = len(left_labels)/len(feature)\n",
    "    right_len = len(right_labels)/len(feature)\n",
    "\n",
    "    #Calculating the impurity measure for the feature and each split, and multiplying with the split ratio\n",
    "    impurity_left = impurity(left_labels, impurity_measure)*left_len\n",
    "    impurity_right = impurity(right_labels, impurity_measure)*right_len\n",
    "\n",
    "    #returning the conditional entropy\n",
    "    return impurity_left + impurity_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1194033f-f4f4-4e0b-99da-b8e0ea693c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigation_score(feature, labels, impurity_measure='entropy'):\n",
    "\n",
    "    #Getting the entropies\n",
    "    entropy_feature = impurity(labels, impurity_measure)\n",
    "    cond_entropy_feature = cond_impurity(feature, labels, impurity_measure)\n",
    "\n",
    "    #Returning the investigation score\n",
    "    return entropy_feature - cond_entropy_feature\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ee1c9-b929-455d-a2d6-74224314091f",
   "metadata": {},
   "source": [
    "### Finding the best feature to split on, by investigation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c8a4a07-63fd-408f-9237-df50026d30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_feature(data, labels, impurity_measure = 'entropy'):\n",
    "    #Making a dictionary to store the feature key and the inv_score as value. \n",
    "    best_i = {}\n",
    "    #Iterating through each feature\n",
    "    for feature in range(data.shape[1]):\n",
    "        best_i[feature] = investigation_score(data[:, feature], labels, impurity_measure)\n",
    "\n",
    "    #Finding best feature with max function, where the key is the values. \n",
    "    #print(best_i.values())\n",
    "    #if max(best_i.values()) > 0:\n",
    "    best_feature_index = max(best_i, key= best_i.get)\n",
    "    return best_feature_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef99aa0-f964-4807-bf66-c9368154eeec",
   "metadata": {},
   "source": [
    "### Splitting the data and labels into subarrays\n",
    "I chose to return a triple containing the left side, right side and value for the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61801dbf-9f79-4780-ab34-a3ae511f9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, labels, impurity_measure = 'entropy', feature_index='best', feature_mean='best'):\n",
    "    \n",
    "    #If we want to find best_feature or use a predetermined\n",
    "    if feature_index == 'best':\n",
    "        feature_index = find_best_feature(data, labels, impurity_measure)\n",
    "        best_feature_mean = 'best'\n",
    "\n",
    "    #Get the feature\n",
    "    best_feature = data[:, feature_index]\n",
    "\n",
    "    #Splitting the labels | Could have returned the labels in investigation_score to save compute, but this should be marginal.\n",
    "    left_labels, right_labels, best_feature_mean = split_label(best_feature, labels)  \n",
    "    \n",
    "    #Splitting the data based on the indexes of what points is lower or higher than mean, given specific feature\n",
    "    left_data = data[best_feature < best_feature_mean]\n",
    "    right_data = data[best_feature >= best_feature_mean]\n",
    "    \n",
    "    #Returning a 3-tuple consisting of the left side, the right side and information about the split (what feature, the mean)\n",
    "    #The latter will be stored in each branch when building the tree. \n",
    "    return (left_data, left_labels), (right_data, right_labels), (feature_index, best_feature_mean)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0cae93-4c02-41a4-86ec-b6b2629c5685",
   "metadata": {},
   "source": [
    "### Checking for identical features\n",
    "The approach is if there is only one unique value in every column, then the multi array has identical rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68c5f8f2-a3ee-4cb8-b950-e61c9a892610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identical_features(data, labels):\n",
    "    count = 0\n",
    "    for feature in range(data.shape[1]):\n",
    "        if len(np.unique(data[:,feature])) == 1:\n",
    "            count += 1\n",
    "    \n",
    "    if count == data.shape[1]:\n",
    "        uniques, counts = np.unique(labels, return_counts=True)\n",
    "        return uniques[np.argmax(counts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f482b-d36e-4c45-af7e-f9be017dabd4",
   "metadata": {},
   "source": [
    "## Implementing the ID3 function by using the prior built functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61eb97a8-1a75-45bc-a0f3-3ed7c568316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(data, labels, tree, impurity_measure = 'entropy'):\n",
    "    #Finding checking for identical features\n",
    "    identical = identical_features(data, labels)\n",
    "    \n",
    "    #If all data points have the same label:\n",
    "    if impurity(labels) == 0:\n",
    "        tree.value = labels[0]\n",
    "        return labels[0]\n",
    "\n",
    "    #Else if all data points have identical feature values\n",
    "    elif identical != None:\n",
    "        tree.value = identical\n",
    "        return\n",
    "\n",
    "\n",
    "    #Else\n",
    "    else:\n",
    "        #Extracting the information from the split\n",
    "        left, right, root = split_data(data, labels, impurity_measure)\n",
    "\n",
    "        if root != 0:\n",
    "            #Setting this root to indicate the split\n",
    "            tree.value = root\n",
    "    \n",
    "            #Making left branch\n",
    "            new_left = Tree()\n",
    "            tree.left = new_left\n",
    "            id3(left[0], left[1], new_left, impurity_measure)\n",
    "    \n",
    "            #Making right branch\n",
    "            new_right = Tree()\n",
    "            tree.right = new_right \n",
    "            id3(right[0], right[1], new_right, impurity_measure)\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb721d-f322-4d49-88ee-0907d4dc661e",
   "metadata": {},
   "source": [
    "## Creating some functions to inspect the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b2b94a1-0c6a-44d6-b6f0-ed31e092fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tree(tree,count=0):\n",
    "    if tree != None:\n",
    "        counts = count\n",
    "        counts += 1\n",
    "        print(tree.value)\n",
    "    \n",
    "        search_tree(tree.left,counts)\n",
    "        search_tree(tree.right,counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8408223a-20e0-4cf5-97c8-adbe5838010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_nodes(tree):\n",
    "    if tree == None:\n",
    "        return 0\n",
    "\n",
    "    l = total_nodes(tree.left)\n",
    "    r = total_nodes(tree.right)\n",
    "\n",
    "    return 1 + l + r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059cb26c-d81d-4a74-a66b-10c7a1935090",
   "metadata": {},
   "source": [
    "## Prediction and accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31585334-147f-4159-a803-00a0041c0775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_point, tree):\n",
    "    if type(tree.value) == tuple:\n",
    "        feature, split_point = tree.value\n",
    "        if data_point[feature] < split_point:\n",
    "            return predict(data_point, tree.left)\n",
    "        else:\n",
    "            return predict(data_point, tree.right)\n",
    "    else:\n",
    "        return tree.value\n",
    "    #print(tree.value)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8021b256-a18f-48b2-ba30-a9170288fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(data, labels, tree):\n",
    "    labels_len = len(labels)\n",
    "    if labels_len == 0:\n",
    "        return 0\n",
    "    count = 0\n",
    "    for counts, data_point in enumerate(data):\n",
    "        if predict(data_point, tree) == labels[counts]:\n",
    "            count += 1\n",
    "    return count/labels_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "620bb807-8adc-44bf-b06e-422ce1705769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_flat_label(data, labels, prediction=0):\n",
    "    labels_len = len(labels)\n",
    "    if labels_len == 0:\n",
    "        return 0\n",
    "    count = 0\n",
    "    for counts, data_points in enumerate(data):\n",
    "        if prediction == labels[counts]:\n",
    "            count += 1\n",
    "    return count/labels_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef7317-4367-4478-ad61-7f8277c6625f",
   "metadata": {},
   "source": [
    "## Pruning algorithm\n",
    "In essence a Depth first search. Since I implemented the tree structure to have a left and right child, I dont have a child list. But it works the same since when using a for loop on a list of children, you start with the first one and its first one etc. So I'm doing left side first, then calling right side when the left is searched. Instead of for loop im just using running it recusively as long as the child is a tree object. Then on each child im calculating if the accuracy is higher with a lable instead of a split, and if so, the new value is a label.\n",
    "\n",
    "If there is an empty array, then I'm not changing its branch. This is because the pruning data does not have the same data points as the training data. But when you calculate the accuracy and predictions with labels, they are all 0%. So the pruning data is not really suitable to determine wheter this split is necesarry or not. I have done some observations with different seeds and on average the accuracy declines when pruning these empty arrays. Hence im leaving the branches untouched.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe8949d9-f022-4fa1-be44-71f2b4cfd408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(data, labels, tree, impurity_measure = 'entropy'):\n",
    "    #Just want to do the pruning on a node that is splitting, not on a label node.\n",
    "    if type(tree.value) == tuple:\n",
    "        feature, mean = tree.value\n",
    "\n",
    "        #Incase there are empty branches. If the the data and labels are empty, then there is no reason to split it, so the datapoints can stay as they were.\n",
    "        #Since the accuracy is 0 with given data, but also 0 for either 0 or 1, so it would be unfair to choose one, because there is not enough data in pruning, to make a good decision.\n",
    "        if len(labels) == 0:\n",
    "            return\n",
    "        else:\n",
    "            left, right, values = split_data(data, labels, impurity_measure, feature_index = feature)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #If there is a left \n",
    "        if type(tree.left) == Tree:\n",
    "            prune(left[0], left[1], tree.left)\n",
    "        if type(tree.right) == Tree:\n",
    "            prune(right[0], right[1], tree.right)\n",
    "\n",
    "        #Accuracy of either splitting or giving hard label\n",
    "        for label in [0,1]:\n",
    "            if predict_flat_label(data, labels, prediction=label) > accuracy(data, labels, tree):\n",
    "                #print('true')\n",
    "                #print(tree.value, left[1], right[1], predict_flat_label(data, labels, prediction=label), accuracy(data, labels, tree))\n",
    "                tree.value = label\n",
    "                tree.left, tree.right = None, None\n",
    "                #print(tree.value)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8765ca3-3a21-49f1-a2f0-68a3e7583f37",
   "metadata": {},
   "source": [
    "# The main learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46abd623-47e2-4eac-9b2d-84f6b9df45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the id3 algorithm to return a decision tree.\n",
    "def learn(X, y, impurity_measure='entropy', pruning=\"false\", ratio=0.8):\n",
    "    #Making the root for the tree\n",
    "    tree = Tree()\n",
    "\n",
    "    #Checking whether the pruning is true\n",
    "    if pruning == 'True':\n",
    "        #Now we need to split the data\n",
    "        ratio = ratio\n",
    "        X_train, X_prune = np.split(X, [int(ratio*len(X))])\n",
    "        y_train, y_prune = np.split(y, [int(ratio*len(y))])\n",
    "\n",
    "        #Making the tree with training data\n",
    "        id3(X_train, y_train, tree, impurity_measure)\n",
    "        total_nodes(tree)\n",
    "\n",
    "        #Pruning the tree with the pruning data\n",
    "        prune(X_prune, y_prune, tree)\n",
    "        total_nodes(tree)\n",
    "\n",
    "        #Returning the pruned tree\n",
    "        return tree\n",
    "    \n",
    "    #Else if pruning is false | Just make the tree and return it.\n",
    "    else:\n",
    "        id3(X, y, tree, impurity_measure)\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a41d14-ea49-40e8-a4b9-c1a5305851b2",
   "metadata": {},
   "source": [
    "### read csv to numpy\n",
    "Nice to have if we want to load more datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9a9b874-9cc6-4e6e-b242-72ecbf8b54f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvs_numpy(name=''):\n",
    "    with open(name, 'r') as r:\n",
    "        reader = csv.reader(r)\n",
    "        data = list(reader)\n",
    "    \n",
    "    feature_names = data[0][:-1]\n",
    "    data_ar = np.array(data[1:], dtype=float)\n",
    "    targets = data_ar[:, -1]\n",
    "    data = data_ar[:, :-1]\n",
    "    return data, targets, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2522610c-45c7-4a14-9db2-fa72d2606ae9",
   "metadata": {},
   "source": [
    "# Testing withthe wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48f03310-43a1-4880-88d5-1a6ce72b65e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels, target_names = cvs_numpy('wine_dataset.csv')\n",
    "seed = 521#332#333#521\n",
    "X_train, X_val_test, y_train, y_val_test = model_selection.train_test_split(data, labels, test_size=0.3, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2718a890-0210-40ae-973b-3418c26b2500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.13,  1.6 ,  3.34,  0.59,  9.2 ],\n",
       "        [ 0.1 ,  2.8 ,  3.6 ,  0.66, 10.2 ],\n",
       "        [ 0.32,  1.9 ,  3.2 ,  0.55,  9.5 ],\n",
       "        ...,\n",
       "        [ 0.44,  1.6 ,  3.38,  0.86,  9.9 ],\n",
       "        [ 0.36,  4.5 ,  3.4 ,  0.57, 10.4 ],\n",
       "        [ 0.34,  6.4 ,  2.99,  0.4 , 10.8 ]]),\n",
       " array([1., 1., 1., ..., 1., 0., 0.]),\n",
       " ['citric acid', 'residual sugar', 'pH', 'sulphates', 'alcohol'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels, target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ce9c04f-32e7-4f01-a07e-812d6967a4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = Tree()\n",
    "tree= learn(X_train, y_train, impurity_measure='entropy')\n",
    "accuracy(X_train, y_train, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b7dd259-0c09-495b-9dab-a54ce7a6467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Tree()\n",
    "tree= learn(X_train, y_train, impurity_measure='gini', pruning=\"True\", ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bdca0d5a-986e-4087-91df-dddde5c0329d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.left.left.value\n",
    "total_nodes(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49d65284-b147-46eb-899f-5a0eea945b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9168900804289544"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(X_train, y_train, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a64d2b9-ecc0-4ac0-9b1f-324e5f569b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8583333333333333"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(X_val_test, y_val_test, tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bacfe6e5-7ddd-4e6e-9049-d2235475dbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(781, 0.8635416666666667)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_2 = Tree()\n",
    "tree_2 = learn(X_train, y_train, impurity_measure='gini')\n",
    "\n",
    "total_nodes(tree_2), accuracy(X_val_test, y_val_test, tree_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8efe678-bc7f-4d13-b791-67f5741f707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prune(X_val_test, y_val_test, tree_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b98562f6-24d6-4fa8-94c5-eb7c7d04fba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "781"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_nodes(tree_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2faab63-d517-4297-b9fb-6959dd40500f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.0, 1), (0.8635416666666667, 781))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(accuracy(X_val_test, y_val_test, tree), total_nodes(tree)), (accuracy(X_val_test, y_val_test, tree_2), total_nodes(tree_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "24878026-ad7b-45ff-89e6-36fa4a1743a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.496875"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_flat_label(X_val_test, y_val_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "507bf71e-3f2f-4809-8f88-c26495cb55bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ratio: 0.1, with impurity_measure: gini, accuracy: 0.872 | Difference in accuracy: 0.00729\n",
      "Testing ratio: 0.2, with impurity_measure: gini, accuracy: 0.850 | Difference in accuracy: -0.01458\n",
      "Testing ratio: 0.3, with impurity_measure: gini, accuracy: 0.866 | Difference in accuracy: 0.00104\n",
      "Testing ratio: 0.4, with impurity_measure: gini, accuracy: 0.868 | Difference in accuracy: 0.00312\n",
      "Testing ratio: 0.5, with impurity_measure: gini, accuracy: 0.857 | Difference in accuracy: -0.00729\n",
      "Testing ratio: 0.6, with impurity_measure: gini, accuracy: 0.858 | Difference in accuracy: -0.00625\n",
      "Testing ratio: 0.7, with impurity_measure: gini, accuracy: 0.878 | Difference in accuracy: 0.01354\n",
      "Testing ratio: 0.8, with impurity_measure: gini, accuracy: 0.868 | Difference in accuracy: 0.00312\n",
      "Testing ratio: 0.9, with impurity_measure: gini, accuracy: 0.866 | Difference in accuracy: 0.00104\n"
     ]
    }
   ],
   "source": [
    "tree_prunefree = Tree()\n",
    "tree_prunefree = learn(X_train, y_train, impurity_measure='entropy')\n",
    "accuracy_prunefree = accuracy(X_val_test, y_val_test, tree_prunefree)\n",
    "for x in range(1,10):\n",
    "    tree = Tree()\n",
    "    tree = learn(X_train, y_train, impurity_measure='entropy', pruning='True', ratio=x/10)\n",
    "    accuracy_tree = accuracy(X_val_test, y_val_test, tree)\n",
    "    print(f'Testing ratio: {x/10}, with impurity_measure: gini, accuracy: {accuracy_tree:.3f} | Difference in accuracy: {accuracy_tree- accuracy_prunefree:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf1b58-5b65-4975-a044-9053517f3241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b9427e-2bf8-4da2-b81e-d1c02bec1a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
