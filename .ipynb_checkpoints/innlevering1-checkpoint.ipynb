{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce77f734-cae6-4ec2-aace-df325a9cd059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import neighbors, datasets, model_selection, metrics, __version__\n",
    "from sklearn import tree as sk_tree\n",
    "from math import log2\n",
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3c957-8259-42d2-9d48-b2979142b52a",
   "metadata": {},
   "source": [
    "## Creating the the different functions.\n",
    "\n",
    "### starting with the tree class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f606655-3fed-4eec-98a4-28c817bb71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple tree structure with maximum 2 children\n",
    "class Tree:\n",
    "    #Containing a value, either a lable or tuple with information about split. Then each child is a new tree object.\n",
    "    def __init__(self, value=None):\n",
    "        self.value = value\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.major_label = None\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb588e-5882-490a-8568-964ed07423cf",
   "metadata": {},
   "source": [
    "### Split labels\n",
    "Making a function to split a list of labels on its mean. The split function is too simple, because it would split it on the datapoint with the mean.\n",
    "I could sort the array, but I find it more simple and effective to retrieve the indexes instead and slice the points from the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20f245af-d101-4dba-9348-f1081e6ea2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_label_mean(feature, labels):\n",
    "    #Finding feature mean\n",
    "    feature_mean = np.nanmean(feature)\n",
    "    #Splitting the feature on the mean\n",
    "    left_labels = labels[np.nonzero(feature < feature_mean)]\n",
    "    right_labels = labels[np.nonzero(feature >= feature_mean)]\n",
    "    #np.nonzero function finds the index in an array with a condition. Here the conditions are based on the mean.\n",
    "    return left_labels, right_labels, feature_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c9899cf-0a7d-4c27-b616-38dbd1b161e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_label(feature, labels, split_point):\n",
    "    #Splitting the feature on the split_point\n",
    "    left_labels = labels[np.nonzero(feature < split_point)]\n",
    "    right_labels = labels[np.nonzero(feature >= split_point)]\n",
    "    #np.nonzero function finds the index in an array with a condition. Here the conditions are based on the mean.\n",
    "    return left_labels, right_labels, split_point\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d8f850-8419-4bea-8ad3-845492dfd053",
   "metadata": {},
   "source": [
    "### Impurity and investigation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af6fd92b-c37e-4ee3-882a-3879c8695669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impurity(arr, impurity_measure = 'entropy'):\n",
    "    #Starting sum\n",
    "    entropy = 0\n",
    "    gini = 0\n",
    "    #Finding the counts for each possible label. Eihter one or two labels. \n",
    "    labels, counts = np.unique(arr, return_counts=True)\n",
    "    #Calculating the entropy and gini for the array\n",
    "    for count in counts:\n",
    "        prob = count/len(arr)\n",
    "        entropy -= prob*log2(prob)\n",
    "        gini += prob*(1-prob)\n",
    "\n",
    "    if impurity_measure == 'entropy':\n",
    "        return entropy\n",
    "    elif impurity_measure == 'gini':\n",
    "        return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f2b1d26-d624-4935-88c2-538d59b71ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_impurity(feature, labels, split_point, impurity_measure='entropy'):\n",
    "    #Finding mean\n",
    "    \n",
    "    #Getting the labels for the split\n",
    "    left_labels, right_labels, f_mean = split_label(feature, labels, split_point=feature.mean())\n",
    "    \n",
    "    #Finding the count of labels on each side\n",
    "    left_len = len(left_labels)/len(feature)\n",
    "    right_len = len(right_labels)/len(feature)\n",
    "\n",
    "    #Calculating the impurity measure for the feature and each split, and multiplying with the split ratio\n",
    "    impurity_left = impurity(left_labels, impurity_measure)*left_len\n",
    "    impurity_right = impurity(right_labels, impurity_measure)*right_len\n",
    "\n",
    "    #returning the conditional entropy\n",
    "    return impurity_left + impurity_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1194033f-f4f4-4e0b-99da-b8e0ea693c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigation_score(feature, labels, split_point, impurity_measure='entropy'):\n",
    "\n",
    "    #Getting the entropies\n",
    "    entropy_feature = impurity(labels, impurity_measure)\n",
    "    cond_entropy_feature = cond_impurity(feature, labels, impurity_measure)\n",
    "\n",
    "    #Returning the investigation score\n",
    "    return entropy_feature - cond_entropy_feature\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ee1c9-b929-455d-a2d6-74224314091f",
   "metadata": {},
   "source": [
    "### Finding the best feature to split on, by investigation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c8a4a07-63fd-408f-9237-df50026d30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_feature(data, labels, split_point, impurity_measure = 'entropy'):\n",
    "    #Making a dictionary to store the feature key and the inv_score as value. \n",
    "    best_i = {}\n",
    "    #Iterating through each feature\n",
    "    for feature in range(data.shape[1]):\n",
    "        best_i[feature] = investigation_score(data[:, feature], labels, split_point, impurity_measure=impurity_measure)\n",
    "\n",
    "    #Finding best feature with max function, where the key is the values. \n",
    "    #print(best_i.values())\n",
    "    #if max(best_i.values()) > 0:\n",
    "    best_feature_index = max(best_i, key= best_i.get)\n",
    "    return best_feature_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef99aa0-f964-4807-bf66-c9368154eeec",
   "metadata": {},
   "source": [
    "### Splitting the data and labels into subarrays\n",
    "I chose to return a triple containing the left side, right side and value for the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61801dbf-9f79-4780-ab34-a3ae511f9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, labels, impurity_measure = 'entropy', feature_index='best', feature_mean='best'):\n",
    "    \n",
    "    #If we want to find best_feature or use a predetermined\n",
    "    if feature_index == 'best':\n",
    "        feature_index = find_best_feature(data, labels, impurity_measure)\n",
    "        best_feature_mean = 'best'\n",
    "\n",
    "    #Get the feature\n",
    "    best_feature = data[:, feature_index]\n",
    "\n",
    "    #Splitting the labels | Could have returned the labels in investigation_score to save compute, but this should be marginal.\n",
    "    left_labels, right_labels, best_feature_mean = split_label_mean(best_feature, labels)  \n",
    "    \n",
    "    #Splitting the data based on the indexes of what points is lower or higher than mean, given specific feature\n",
    "    left_data = data[best_feature < best_feature_mean]\n",
    "    right_data = data[best_feature >= best_feature_mean]\n",
    "    \n",
    "    #Returning a 3-tuple consisting of the left side, the right side and information about the split (what feature, the mean)\n",
    "    #The latter will be stored in each branch when building the tree. \n",
    "    return (left_data, left_labels), (right_data, right_labels), (feature_index, best_feature_mean)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2b5c15c8-1225-4c78-8f2b-4d6502133dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_new(data, labels, impurity_measure='entropy', split_point='find', feature_index='find'):\n",
    "    #If we want to find best_feature or use a predetermined\n",
    "    if feature_index == 'find':\n",
    "        feature_index = find_best_feature(data, labels, impurity_measure)\n",
    "        split_point = 'find'\n",
    "    \n",
    "    #Get the feature\n",
    "    split_feature = data[:, feature_index]\n",
    "\n",
    "    if split_point == 'find':\n",
    "        split_point = split_feature.mean()\n",
    "\n",
    "    #Splitting the labels | Could have returned the labels in investigation_score to save compute, but this should be marginal.\n",
    "    left_labels, right_labels, split_point = split_label(split_feature, labels, split_point)  \n",
    "    \n",
    "    #Splitting the data based on the indexes of what points is lower or higher than mean, given specific feature\n",
    "    left_data = data[split_feature < split_point]\n",
    "    right_data = data[split_feature >= split_point]\n",
    "    \n",
    "    #Returning a 3-tuple consisting of the left side, the right side and information about the split (what feature, the mean)\n",
    "    #The latter will be stored in each branch when building the tree. \n",
    "    return (left_data, left_labels), (right_data, right_labels), (feature_index, split_point)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0cae93-4c02-41a4-86ec-b6b2629c5685",
   "metadata": {},
   "source": [
    "### Checking for identical features\n",
    "The approach is if there is only one unique value in every column, then the multi array has identical rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "68c5f8f2-a3ee-4cb8-b950-e61c9a892610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identical_features(data, labels):\n",
    "    count = 0\n",
    "    for feature in range(data.shape[1]):\n",
    "        if len(np.unique(data[:,feature])) == 1:\n",
    "            count += 1\n",
    "    \n",
    "    if count == data.shape[1]:\n",
    "        uniques, counts = np.unique(labels, return_counts=True)\n",
    "        return uniques[np.argmax(counts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f482b-d36e-4c45-af7e-f9be017dabd4",
   "metadata": {},
   "source": [
    "## Implementing the ID3 function by using the prior built functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "61eb97a8-1a75-45bc-a0f3-3ed7c568316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(data, labels, tree, impurity_measure = 'entropy', split='mean'):\n",
    "    #Finding checking for identical features\n",
    "    identical = identical_features(data, labels)\n",
    "    \n",
    "    #If all data points have the same label:\n",
    "    if impurity(labels) == 0:\n",
    "        tree.value = labels[0]\n",
    "        return labels[0]\n",
    "\n",
    "    #Else if all data points have identical feature values\n",
    "    elif identical != None:\n",
    "        tree.value = identical\n",
    "        return\n",
    "\n",
    "\n",
    "    #Else\n",
    "    else:\n",
    "        #Extracting the information from the split\n",
    "        left, right, root = split_data(data, labels, impurity_measure=impurity_measure)\n",
    "\n",
    "        if root != 0:\n",
    "            #Setting this root to indicate the split\n",
    "            tree.value = root\n",
    "\n",
    "            #Setting the majority label\n",
    "            lab, counts = np.unique(labels, return_counts=True)\n",
    "            maj_index = np.where(counts == max(counts))[0][0]\n",
    "            tree.majority_label = lab[maj_index]\n",
    "    \n",
    "            #Making left branch\n",
    "            new_left = Tree()\n",
    "            tree.left = new_left\n",
    "            id3(left[0], left[1], new_left, impurity_measure)\n",
    "    \n",
    "            #Making right branch\n",
    "            new_right = Tree()\n",
    "            tree.right = new_right \n",
    "            id3(right[0], right[1], new_right, impurity_measure)\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb721d-f322-4d49-88ee-0907d4dc661e",
   "metadata": {},
   "source": [
    "## Creating some functions to inspect the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7b2b94a1-0c6a-44d6-b6f0-ed31e092fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tree(tree,count=0):\n",
    "    if tree != None:\n",
    "        counts = count\n",
    "        counts += 1\n",
    "        print(tree.value)\n",
    "    \n",
    "        search_tree(tree.left,counts)\n",
    "        search_tree(tree.right,counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8408223a-20e0-4cf5-97c8-adbe5838010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_nodes(tree):\n",
    "    if tree == None:\n",
    "        return 0\n",
    "\n",
    "    l = total_nodes(tree.left)\n",
    "    r = total_nodes(tree.right)\n",
    "\n",
    "    return 1 + l + r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059cb26c-d81d-4a74-a66b-10c7a1935090",
   "metadata": {},
   "source": [
    "## Prediction and accuracy functions\n",
    "\n",
    "Because I implemented the tree structure with binary tree properties, then searching the tree will be in O(logn) time. This makes the pruning really efficient. The predict function works like a binary search. It goes under or over a value in a given feature untill it has found a leaf node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "31585334-147f-4159-a803-00a0041c0775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_point, tree):\n",
    "    #Only the leaf node is not a tuple. So go through all the tuples and go leaft or right until you reach a leaf\n",
    "    while type(tree.value) == tuple: #and tree.value != None | is unecesarry since every split has a child or is a leaf. So it wont trigger non leafs or splits\n",
    "        feature, split_point = tree.value\n",
    "        if data_point[feature] < split_point:\n",
    "            tree = tree.left\n",
    "        else:\n",
    "            tree = tree.right\n",
    "\n",
    "    #When you reach a leaf, return the value/label\n",
    "    else:\n",
    "        return tree.value\n",
    "    #print(tree.value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5516f7fe-07d3-442b-bd31-568743f2cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_accuracy(data, labels, tree):\n",
    "    #Make an array of all the predictions for the data_points, with given tree, then return the ratio of correctly labled predictions. \n",
    "    predictions = np.array([predict(data_point, tree) for data_point in data])\n",
    "    return len(predictions[predictions == labels])/len(labels)\n",
    "\n",
    "#I was contemplating wheter it was possible to optimize with vectorization, but since data is a multi-dim array, then it would be more tricky.\n",
    "#I concluded that using list comprehension was more pythonic. And the check with extracting correctely labled predictions with np is quite efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "620bb807-8adc-44bf-b06e-422ce1705769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_accuracy(labels, prediction):\n",
    "    return len(labels[labels == prediction])/len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef7317-4367-4478-ad61-7f8277c6625f",
   "metadata": {},
   "source": [
    "## Pruning algorithm\n",
    "In essence a Depth first search. Since I implemented the tree structure to have a left and right child, I dont have a child list. But it works the same since when using a for loop on a list of children, you start with the first one and its first one etc. So I'm doing left side first, then calling right side when the left is searched. Instead of for loop im just using running it recusively as long as the child is a tree object. Then on each child im calculating if the accuracy is higher with a lable instead of a split, and if so, the new value is a label.\n",
    "\n",
    "If there is an empty array, then I'm not changing its branch. This is because the pruning data does not have the same data points as the training data. But when you calculate the accuracy and predictions with labels, they are all 0%. So the pruning data is not really suitable to determine wheter this split is necesarry or not. I have done some observations with different seeds and on average the accuracy declines when pruning these empty arrays. Hence im leaving the branches untouched.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fe8949d9-f022-4fa1-be44-71f2b4cfd408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(data, labels, tree, impurity_measure = 'entropy'):\n",
    "    #Just want to do the pruning on a node that is splitting, not on a label node.\n",
    "    if type(tree.value) == tuple:\n",
    "        feature, mean = tree.value\n",
    "\n",
    "        #Incase there are empty branches. If the the data and labels are empty, then there is no reason to split it, so the datapoints can stay as they were.\n",
    "        #Since the accuracy is 0 with given data, but also 0 for either 0 or 1, so it would be unfair to choose one, because there is not enough data in pruning, to make a good decision.\n",
    "        if len(labels) == 0:\n",
    "            return\n",
    "        else:\n",
    "            left, right, values = split_data_new(data, labels, impurity_measure=impurity_measure, feature_index = feature, split_point=mean)\n",
    "\n",
    "        \n",
    "        #If there is a left \n",
    "        if type(tree.left) == Tree:\n",
    "            prune(left[0], left[1], tree.left)\n",
    "        if type(tree.right) == Tree:\n",
    "            prune(right[0], right[1], tree.right)\n",
    "\n",
    "        #Accuracy of either splitting or giving hard label\n",
    "        #If the accuracy of majority class is greater than the prediction of subtree, then replace the subtree with the majority lable. Also remove children.\n",
    "        if majority_accuracy(labels, tree.majority_label) >= tree_accuracy(data, labels, tree):\n",
    "            #print('true')\n",
    "            #print(tree.value, left[1], right[1], predict_flat_label(data, labels, prediction=label), accuracy(data, labels, tree))\n",
    "            tree.value = tree.majority_label\n",
    "            tree.left, tree.right = None, None\n",
    "            #print(tree.value)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8765ca3-3a21-49f1-a2f0-68a3e7583f37",
   "metadata": {},
   "source": [
    "# The main learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "46abd623-47e2-4eac-9b2d-84f6b9df45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the id3 algorithm to return a decision tree.\n",
    "def learn(X, y, impurity_measure='entropy', pruning=False, train_ratio=0.8):\n",
    "    #Making the root for the tree\n",
    "    tree = Tree()\n",
    "\n",
    "    #Checking whether the pruning is true\n",
    "    if pruning == True:\n",
    "        #Now we need to split the data\n",
    "        train_ratio = train_ratio\n",
    "        X_train, X_prune = np.split(X, [int(train_ratio*len(X))])\n",
    "        y_train, y_prune = np.split(y, [int(train_ratio*len(y))])\n",
    "\n",
    "        #Making the tree with training data\n",
    "        id3(X_train, y_train, tree, impurity_measure)\n",
    "        total_nodes(tree)\n",
    "\n",
    "        #Pruning the tree with the pruning data\n",
    "        prune(X_prune, y_prune, tree)\n",
    "        total_nodes(tree)\n",
    "\n",
    "        #Returning the pruned tree\n",
    "        return tree\n",
    "    \n",
    "    #Else if pruning is false | Just make the tree and return it.\n",
    "    else:\n",
    "        id3(X, y, tree, impurity_measure)\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a41d14-ea49-40e8-a4b9-c1a5305851b2",
   "metadata": {},
   "source": [
    "### read csv to numpy\n",
    "Nice to have if we want to load more datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c9a9b874-9cc6-4e6e-b242-72ecbf8b54f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvs_numpy(name=''):\n",
    "    with open(name, 'r') as r:\n",
    "        reader = csv.reader(r)\n",
    "        data = list(reader)\n",
    "    \n",
    "    feature_names = data[0][:-1]\n",
    "    data_ar = np.array(data[1:], dtype=float)\n",
    "    targets = data_ar[:, -1]\n",
    "    data = data_ar[:, :-1]\n",
    "    return data, targets, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2522610c-45c7-4a14-9db2-fa72d2606ae9",
   "metadata": {},
   "source": [
    "# Testing withthe wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "48f03310-43a1-4880-88d5-1a6ce72b65e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels, target_names = cvs_numpy('wine_dataset.csv')#\n",
    "seed = 333#332#333#521\n",
    "X_train, X_val_test, y_train, y_val_test = model_selection.train_test_split(data, labels, test_size=0.3, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2718a890-0210-40ae-973b-3418c26b2500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.13,  1.6 ,  3.34,  0.59,  9.2 ],\n",
       "        [ 0.1 ,  2.8 ,  3.6 ,  0.66, 10.2 ],\n",
       "        [ 0.32,  1.9 ,  3.2 ,  0.55,  9.5 ],\n",
       "        ...,\n",
       "        [ 0.44,  1.6 ,  3.38,  0.86,  9.9 ],\n",
       "        [ 0.36,  4.5 ,  3.4 ,  0.57, 10.4 ],\n",
       "        [ 0.34,  6.4 ,  2.99,  0.4 , 10.8 ]]),\n",
       " array([1., 1., 1., ..., 1., 0., 0.]),\n",
       " ['citric acid', 'residual sugar', 'pH', 'sulphates', 'alcohol'])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels, target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9ce9c04f-32e7-4f01-a07e-812d6967a4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.7377147674560547, accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tree= learn(X_train, y_train, impurity_measure='gini')\n",
    "accu = tree_accuracy(X_train, y_train, tree)\n",
    "ending = time.time()\n",
    "print(f'Time: {ending-start}, accuracy: {accu}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5b7dd259-0c09-495b-9dab-a54ce7a6467b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.3968312740325928, accuracy: 0.9311885612153709\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tree= learn(X_train, y_train, impurity_measure='gini', pruning=True, train_ratio=0.7)\n",
    "accu = tree_accuracy(X_train, y_train, tree)\n",
    "ending = time.time()\n",
    "print(f'Time: {ending-start}, accuracy: {accu}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae239a5-5906-4f17-b242-9ecb38387011",
   "metadata": {},
   "source": [
    "It is taking shorter with pruning because it is training with less training data\n",
    "\n",
    "### prior output: pruning takes 0.017923593521118164s\n",
    "prune_start = time.time()\n",
    "prune_end = time.time()\n",
    "print(f'pruning takes {prune_end-prune_start}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bdca0d5a-986e-4087-91df-dddde5c0329d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.left.left.value\n",
    "total_nodes(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "49d65284-b147-46eb-899f-5a0eea945b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9311885612153709"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_accuracy(X_train, y_train, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9a64d2b9-ecc0-4ac0-9b1f-324e5f569b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8770833333333333"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_accuracy(X_val_test, y_val_test, tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bacfe6e5-7ddd-4e6e-9049-d2235475dbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(757, 0.865625)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_2 = Tree()\n",
    "tree_2 = learn(X_train, y_train, impurity_measure='gini')\n",
    "\n",
    "total_nodes(tree_2), tree_accuracy(X_val_test, y_val_test, tree_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a8efe678-bc7f-4d13-b791-67f5741f707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prune(X_val_test, y_val_test, tree_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b98562f6-24d6-4fa8-94c5-eb7c7d04fba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "757"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_nodes(tree_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b2faab63-d517-4297-b9fb-6959dd40500f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.8770833333333333, 223), (0.865625, 757))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tree_accuracy(X_val_test, y_val_test, tree), total_nodes(tree)), (tree_accuracy(X_val_test, y_val_test, tree_2), total_nodes(tree_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "24878026-ad7b-45ff-89e6-36fa4a1743a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_flat_label(X_val_test, y_val_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "89cf1b58-5b65-4975-a044-9053517f3241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4.440644955300128)\n",
      "(3, 0.6008839779005525)\n",
      "(3, 0.4994230769230769)\n",
      "(3, 0.4223715415019763)\n",
      "(0, 0.31336206896551727)\n",
      "(2, 3.1584375)\n",
      "0.0\n",
      "(1, 2.043548387096774)\n",
      "0.0\n",
      "(1, 2.8714285714285714)\n",
      "(4, 11.299999999999999)\n",
      "0.0\n",
      "(0, 0.24200000000000005)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "(0, 0.26328467153284674)\n",
      "(0, 0.13734375000000001)\n",
      "1.0\n",
      "(4, 10.308796296296297)\n",
      "(2, 3.2412499999999995)\n",
      "(4, 9.536363636363637)\n",
      "(1, 2.5)\n",
      "(1, 1.7)\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "(0, 0.202)\n",
      "1.0\n",
      "(0, 0.225)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "(1, 1.8749999999999998)\n",
      "0.0\n",
      "(2, 3.403333333333333)\n",
      "(2, 3.3274999999999997)\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "(1, 1.86986301369863)\n",
      "0.0\n",
      "(4, 10.574074074074073)\n",
      "(4, 9.760000000000002)\n",
      "1.0\n",
      "(2, 3.271666666666667)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "(0, 0.2374932614555256)\n",
      "(3, 0.5551479289940828)\n",
      "(3, 0.529277108433735)\n",
      "(3, 0.5113333333333333)\n",
      "(0, 0.13444444444444448)\n",
      "1.0\n",
      "(2, 3.191)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "(4, 10.536386138613864)\n",
      "(4, 9.785833333333334)\n",
      "1.0\n",
      "(4, 10.191379310344827)\n",
      "(1, 2.228)\n",
      "(0, 0.30062500000000003)\n",
      "(2, 3.3266666666666667)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "(1, 1.8424242424242423)\n",
      "0.0\n",
      "(0, 0.362)\n",
      "(2, 3.2725)\n",
      "1.0\n",
      "(0, 0.3225)\n",
      "(0, 0.28500000000000003)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "(4, 10.442857142857145)\n",
      "(4, 10.366666666666667)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "(0, 0.3695121951219512)\n",
      "(2, 3.267111111111112)\n",
      "0.0\n",
      "(1, 2.115384615384616)\n",
      "(1, 1.56875)\n",
      "0.0\n",
      "(1, 1.73)\n",
      "(1, 1.6285714285714283)\n",
      "0.0\n",
      "(0, 0.245)\n",
      "1.0\n",
      "0.0\n",
      "(3, 0.54)\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "(0, 0.4643243243243244)\n",
      "(0, 0.40727272727272723)\n",
      "(0, 0.3866666666666667)\n",
      "0.0\n",
      "(1, 1.9)\n",
      "(0, 0.395)\n",
      "1.0\n",
      "0.0\n",
      "(0, 0.39250000000000007)\n",
      "0.0\n",
      "1.0\n",
      "(2, 3.243)\n",
      "(1, 2.0833333333333335)\n",
      "0.0\n",
      "1.0\n",
      "(1, 2.1714285714285713)\n",
      "1.0\n",
      "(1, 2.566666666666667)\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "(2, 3.302142857142857)\n",
      "(0, 0.4027826086956522)\n",
      "(4, 10.6141975308642)\n",
      "(1, 2.11140350877193)\n",
      "(1, 1.6909090909090911)\n",
      "(0, 0.24307692307692308)\n",
      "1.0\n",
      "(1, 1.385714285714286)\n",
      "0.0\n",
      "(0, 0.36750000000000005)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "(2, 3.185686274509804)\n",
      "0.0\n",
      "(2, 3.2519354838709678)\n",
      "(1, 2.0999999999999996)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "(3, 0.7711475409836065)\n",
      "(0, 0.5232911392405064)\n",
      "(2, 3.1733999999999996)\n",
      "(1, 2.1076923076923078)\n",
      "(2, 3.1024999999999996)\n",
      "0.0\n",
      "(1, 1.7249999999999999)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "(0, 0.23663793103448277)\n",
      "1.0\n",
      "(0, 0.3709016393442623)\n",
      "(1, 2.176470588235294)\n",
      "(4, 10.528205128205128)\n",
      "(1, 1.8625)\n",
      "(4, 9.990909090909092)\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "(3, 0.7060000000000001)\n",
      "(2, 3.464444444444444)\n",
      "0.0\n",
      "(2, 3.67)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "(3, 0.5026875)\n",
      "0.0\n",
      "(3, 0.6136125654450262)\n",
      "(1, 9.670075757575757)\n",
      "(4, 10.673777777777778)\n",
      "(4, 9.832520325203252)\n",
      "(3, 0.548095238095238)\n",
      "0.0\n",
      "(1, 7.516666666666666)\n",
      "(1, 5.7)\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "(4, 11.688235294117648)\n",
      "0.0\n",
      "(0, 0.4011764705882353)\n",
      "0.0\n",
      "(0, 0.5275)\n",
      "(0, 0.4779999999999999)\n",
      "0.0\n",
      "1.0\n",
      "(0, 0.61)\n",
      "(0, 0.575)\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "(1, 9.383050847457627)\n",
      "(0, 0.3505128205128205)\n",
      "(3, 0.7725)\n",
      "(2, 3.2636842105263155)\n",
      "0.0\n",
      "(4, 10.066666666666666)\n",
      "0.0\n",
      "(2, 3.3550000000000004)\n",
      "0.0\n",
      "1.0\n",
      "(0, 0.262)\n",
      "(0, 0.185)\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "search_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52926b1a-c4b1-49d2-a39d-abb9ddc711fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_func = np.vectorize(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff803bbc-e1e6-4fc4-a81c-6f6b86a9c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(predictions[predictions == y_test])/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2623f3e7-4034-4632-b202-dfbdd14f6018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8614583333333333, 0.8614583333333333)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predictions = np.array([predict(data_point, tree) for data_point in X_val_test]) \n",
    "tree_accuracy(X_val_test, y_val_test, tree), metrics.accuracy_score(y_val_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "581d184b-6cfd-4ed2-89fb-ec26c0c6d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_flat_label(X_test, y_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "afbe19d1-411f-45f2-9490-c4680cc89853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48541666666666666"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test[y_test == 0])/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad0e88-8f0c-4b09-892b-00b04bc12de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b2be50c-943d-422d-8389-4cde572ae4ab",
   "metadata": {},
   "source": [
    "## Evaluating algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d67518-ae73-46d8-acd9-eac962fb19dd",
   "metadata": {},
   "source": [
    "Assess the performance of your algorithm using an appropriate performance\r\n",
    "measure. Which setting should you select for this data (entropy or Gini,\r\n",
    "pruning or no pruning)? What is your estimate for the performance of\r\n",
    "the selected model on unseen data points? Report how you arrived at the\r\n",
    "conclusi\n",
    "\n",
    "ons.\r\n",
    "Remember to use training, validation, and test sets properly. Note that in the\r\n",
    "model selection step you select one out of the four models (settings) based\r\n",
    "on performance on validation data, and in the model evaluation step you\r\n",
    "evaluate the selected model on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1b527825-eead-4a04-bacf-89b8819af9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test = np.split(X_val_test, [int(len(X_val_test)/2)])\n",
    "y_val, y_test = np.split(y_val_test, [int(len(y_val_test)/2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8ce29ebd-f392-4882-97fa-b2267a2b79ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_ratio(train_data, train_labels, val_data, val_labels, impurity_measure):\n",
    "    tree_prunefree = Tree()\n",
    "    tree_prunefree = learn(train_data, train_labels, impurity_measure=impurity_measure)\n",
    "    accuracy_prunefree = tree_accuracy(val_data, val_labels, tree_prunefree)\n",
    "    #print(f'Prune free accuracy: {accuracy_prunefree}')\n",
    "    ratios = {}\n",
    "    \n",
    "    for x in range(1,10):\n",
    "        tree = Tree()\n",
    "        tree = learn(train_data, train_labels, impurity_measure=impurity_measure, pruning=True, train_ratio=x/10)\n",
    "        accuracy_tree = tree_accuracy(val_data, val_labels, tree)\n",
    "        ratios[x/10] = accuracy_tree\n",
    "        #print(f'Testing training ratio: {x/10}, with impurity_measure: gini, accuracy: {accuracy_tree:.3f} | Difference in accuracy: {accuracy_tree- accuracy_prunefree:.5f}')\n",
    "    ratios[1] = accuracy_prunefree\n",
    "    best_ratio = max(ratios, key=ratios.get)\n",
    "\n",
    "    pruning = False\n",
    "    if best_ratio != 1:\n",
    "        pruning = True\n",
    "    \n",
    "    return [best_ratio, ratios[best_ratio], impurity_measure, pruning]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dbf3d8f3-cffe-46b6-9d8c-a2c9bc6582f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model uses impurity measure: entropy, with pruning: True, training ratio of: 0.7, and an accuracy of: 0.88542\n",
      "True\n",
      "The test accuracy on the best model is: 0.86875\n"
     ]
    }
   ],
   "source": [
    "testing = np.array([best_ratio(X_train, y_train, X_val, y_val, impurity_measure='entropy'),\n",
    "                    best_ratio(X_train, y_train, X_val, y_val, impurity_measure= 'gini')])\n",
    "train_ratio, accuracy, impurity_measure, pruning = testing[np.argmax(testing[:, 1])]\n",
    "print(f'The best model uses impurity measure: {impurity_measure}, with pruning: {pruning}, training ratio of: {train_ratio}, and an accuracy of: {accuracy.astype(float):.5f}')\n",
    "print((pruning))\n",
    "best_tree = learn(X_train, y_train, impurity_measure=impurity_measure, pruning=(pruning=='True'), train_ratio=train_ratio.astype(float))\n",
    "print(f'The test accuracy on the best model is: {tree_accuracy(X_test, y_test, best_tree):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c2037-a61b-4aa2-87c4-73f535002a5c",
   "metadata": {},
   "source": [
    "The best model uses impurity measure: entropy, with pruning: True, training ratio of: 0.7, and an accuracy of: 0.87292\n",
    "True\n",
    "The test accuracy on the best model is: 0.87500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5fdb0d-6be6-43de-8f4d-94fe689cea0b",
   "metadata": {},
   "source": [
    "## SKLEARN test\n",
    "\n",
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "clfs = []\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = sk_tree.DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clfs.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5c0637c1-ddd3-4274-a033-8e35989458b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sk_tree.DecisionTreeClassifier(criterion=\"gini\",)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "#sk_tree.plot_tree(clf)\n",
    "tree = learn(X_train, y_train, impurity_measure='gini')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790c4c6-e5af-4228-873e-81ce68d790e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "40ee4333-bf94-4d5a-84e6-290d3d04ce08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1.0, 0.86875, 0.8770833333333333\n",
      "Accuracy sklearn: 0.8770833333333333\n",
      "Accuracy my implementation: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "train_pred = clf.predict(X_train)\n",
    "val_pred = clf.predict(X_val)\n",
    "test_pred = clf.predict(X_test)\n",
    "\n",
    "train_acc = len(train_pred[train_pred == y_train])/len(y_train)\n",
    "val_acc = len(val_pred[val_pred == y_val])/len(y_val)\n",
    "test_acc =len(test_pred[test_pred == y_test])/len(y_test)\n",
    "print(f'train: {train_acc}, {val_acc}, {test_acc}')\n",
    "print(\"Accuracy sklearn:\",metrics.accuracy_score(y_test, test_pred))\n",
    "val_pred = []\n",
    "for x in X_val:\n",
    "    val_pred.append(predict(x, tree))\n",
    "\n",
    "print(\"Accuracy my implementation:\",metrics.accuracy_score(y_val, val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceac23e-730e-4c30-abcf-3980a4506398",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = [clf.score(X_train, y_train) for clf in clfs]\n",
    "test_scores = [clf.score(X_test, y_test) for clf in clfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e713f08-993c-4061-a962-65a48298c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_scores[np.nonzero(test_scores == max(test_scores))[0][0]], max(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da3090-deb5-43d6-ae54-f5130b46e0d5",
   "metadata": {},
   "source": [
    "## Testing with different dataset\n",
    "found on kaggle: https://www.kaggle.com/datasets/abineshkumark/carsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6fcdf727-76be-40df-9dab-c8b735b58b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>cubicinches</th>\n",
       "      <th>hp</th>\n",
       "      <th>weightlbs</th>\n",
       "      <th>time-to-60</th>\n",
       "      <th>year</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350</td>\n",
       "      <td>165</td>\n",
       "      <td>4209</td>\n",
       "      <td>12</td>\n",
       "      <td>1972</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.9</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>71</td>\n",
       "      <td>1925</td>\n",
       "      <td>14</td>\n",
       "      <td>1980</td>\n",
       "      <td>Europe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>11</td>\n",
       "      <td>1971</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400</td>\n",
       "      <td>150</td>\n",
       "      <td>3761</td>\n",
       "      <td>10</td>\n",
       "      <td>1971</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.5</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>63</td>\n",
       "      <td>2051</td>\n",
       "      <td>17</td>\n",
       "      <td>1978</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>305</td>\n",
       "      <td>130</td>\n",
       "      <td>3840</td>\n",
       "      <td>15</td>\n",
       "      <td>1980</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>36.1</td>\n",
       "      <td>4</td>\n",
       "      <td>91</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16</td>\n",
       "      <td>1979</td>\n",
       "      <td>Japan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232</td>\n",
       "      <td>112</td>\n",
       "      <td>2835</td>\n",
       "      <td>15</td>\n",
       "      <td>1983</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232</td>\n",
       "      <td>100</td>\n",
       "      <td>3288</td>\n",
       "      <td>16</td>\n",
       "      <td>1972</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>105</td>\n",
       "      <td>3353</td>\n",
       "      <td>15</td>\n",
       "      <td>1977</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg   cylinders  cubicinches   hp  weightlbs   time-to-60   year  \\\n",
       "0    14.0           8          350  165       4209           12   1972   \n",
       "1    31.9           4           89   71       1925           14   1980   \n",
       "2    17.0           8          302  140       3449           11   1971   \n",
       "3    15.0           8          400  150       3761           10   1971   \n",
       "4    30.5           4           98   63       2051           17   1978   \n",
       "..    ...         ...          ...  ...        ...          ...    ...   \n",
       "256  17.0           8          305  130       3840           15   1980   \n",
       "257  36.1           4           91   60       1800           16   1979   \n",
       "258  22.0           6          232  112       2835           15   1983   \n",
       "259  18.0           6          232  100       3288           16   1972   \n",
       "260  22.0           6          250  105       3353           15   1977   \n",
       "\n",
       "        brand  \n",
       "0         US.  \n",
       "1     Europe.  \n",
       "2         US.  \n",
       "3         US.  \n",
       "4         US.  \n",
       "..        ...  \n",
       "256       US.  \n",
       "257    Japan.  \n",
       "258       US.  \n",
       "259       US.  \n",
       "260       US.  \n",
       "\n",
       "[261 rows x 8 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cars.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "35972c7e-9fa5-4ebb-a0a7-e8ae4b3b49f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.0, 8, '350', ..., 12, 1972, ' US.'],\n",
       "       [31.9, 4, '89', ..., 14, 1980, ' Europe.'],\n",
       "       [17.0, 8, '302', ..., 11, 1971, ' US.'],\n",
       "       ...,\n",
       "       [22.0, 6, '232', ..., 15, 1983, ' US.'],\n",
       "       [18.0, 6, '232', ..., 16, 1972, ' US.'],\n",
       "       [22.0, 6, '250', ..., 15, 1977, ' US.']], dtype=object)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.to_numpy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ca574c68-ac59-4459-bfd4-750a8ce81218",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[:, -1]\n",
    "data = data[:, :-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bd02e3d4-ed07-4127-b1a7-c26e4e4a01b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.0, 8, '350', ..., '4209', 12, 1972],\n",
       "       [31.9, 4, '89', ..., '1925', 14, 1980],\n",
       "       [17.0, 8, '302', ..., '3449', 11, 1971],\n",
       "       ...,\n",
       "       [22.0, 6, '232', ..., '2835', 15, 1983],\n",
       "       [18.0, 6, '232', ..., '3288', 16, 1972],\n",
       "       [22.0, 6, '250', ..., '3353', 15, 1977]], dtype=object)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2e4df006-c6a7-43db-8000-9c44c9e9b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[:, 2] == ' '] = 0 \n",
    "for x in data[:,2]:\n",
    "    x = int(x)\n",
    "\n",
    "data[:, 2] = data[:, 2].astype(int)\n",
    "\n",
    "data[data[:, 4] == ' '] = 0 \n",
    "for x in data[:,4]:\n",
    "    x = int(x)\n",
    "\n",
    "data[:, 4] = data[:, 4].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9e8e8026-0046-45e4-9bf0-5dd52941968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_label = model_selection.train_test_split(data, labels, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c37b40dc-94dd-4587-9a6a-e893df1c32fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' US.', ' US.', ' US.', ' US.', ' US.', ' US.', ' US.', ' US.',\n",
       "       ' US.', ' Japan.', ' Europe.', ' Japan.', ' US.', ' US.', ' US.',\n",
       "       ' Europe.', ' Europe.', ' Japan.', ' Europe.', ' Japan.', ' US.',\n",
       "       ' US.', ' US.', ' US.', ' US.', ' Japan.', ' US.', ' US.',\n",
       "       ' Europe.', ' US.', ' Japan.', ' US.', ' Europe.', ' Japan.',\n",
       "       ' US.', ' US.', ' Japan.', ' US.', ' US.', ' US.', ' Europe.',\n",
       "       ' US.', ' Europe.', ' Japan.', ' US.', ' US.', ' US.', ' Japan.',\n",
       "       ' Japan.', ' Europe.', ' US.', ' US.', ' Europe.', ' Japan.',\n",
       "       ' US.', ' US.', ' US.', ' Japan.', ' US.', ' US.', ' US.', ' US.',\n",
       "       ' US.', ' Japan.', ' US.', ' Europe.', ' US.', ' Europe.',\n",
       "       ' Europe.', ' US.', ' Japan.', ' US.', ' Europe.', ' US.',\n",
       "       ' Europe.', ' Europe.', ' Europe.', ' Europe.', ' US.', ' US.',\n",
       "       ' Japan.', ' Japan.', ' US.', ' US.', ' Europe.', ' US.',\n",
       "       ' Europe.', ' Europe.', ' Europe.', ' US.', ' US.', ' Japan.',\n",
       "       ' US.', ' US.', ' US.', ' US.', ' US.', ' US.', ' US.', ' Japan.',\n",
       "       ' US.', ' US.', ' US.', ' US.', ' US.', ' US.', ' Europe.', ' US.',\n",
       "       ' US.', ' US.', ' US.', ' US.', ' Japan.', ' Japan.', ' Europe.',\n",
       "       ' US.', ' Japan.', ' US.', ' US.', ' US.', ' US.', ' US.', ' US.',\n",
       "       ' Europe.', ' Japan.', ' US.', ' Europe.', ' Europe.', ' US.',\n",
       "       ' US.', ' US.', ' Europe.', ' Europe.', ' Japan.', ' US.', ' US.',\n",
       "       ' US.', ' US.', ' US.', ' Japan.', ' US.', ' US.', ' Europe.',\n",
       "       ' US.', ' US.', ' Japan.', ' US.', ' Japan.', ' US.', ' Japan.',\n",
       "       ' US.', ' Japan.', ' US.', ' US.', ' US.', ' Europe.', ' Europe.',\n",
       "       ' US.', ' Japan.', ' US.', ' US.', ' US.', ' Europe.', ' US.',\n",
       "       ' Japan.', ' US.', ' US.', ' Europe.', ' Europe.', ' Europe.',\n",
       "       ' Europe.', ' US.', ' US.', ' Europe.', ' US.', ' US.', ' US.',\n",
       "       ' Europe.', ' US.', ' US.', ' US.', ' US.'], dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "15be11a2-74f4-45ed-bc4e-0d80fd8c3624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([' Europe.', ' Japan.', ' US.'], dtype=object),\n",
       " array([ 9, 20, 50], dtype=int64))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_label, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a9bacae7-2bac-45f1-bd62-8e1855389526",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_3 = Tree()\n",
    "tree_3 = learn(train_data, train_labels, impurity_measure='entropy', pruning='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2aa28f47-3f35-4df8-96a3-ea178ba76415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4013498193719667"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impurity(labels[:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e7e68722-5f29-448b-8bbb-54d155f2ca1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9945054945054945"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_accuracy(train_data, train_labels, tree_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "07985698-4b1f-4777-becd-37b74947cc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' US.'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(data[0], tree_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1ed55b4a-d308-459b-847d-fb6a42eb0880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' US.'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c76db938-4c06-4f99-9e29-ac95ec6cfd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_nodes(tree_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "68db35fa-17e7-428b-a109-3b520512059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sk_tree.DecisionTreeClassifier(criterion=\"gini\")\n",
    "\n",
    "clf = clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "156c64d8-1e89-4dec-a031-871869635389",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "05bdcb50-d55e-41a3-a75e-d81dba732147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' US.', ' US.', ' US.', ' US.', ' US.', ' US.', ' US.', ' US.',\n",
       "       ' US.', ' Japan.', ' Europe.', ' Japan.', ' US.', ' US.', ' US.',\n",
       "       ' Europe.', ' Europe.', ' Japan.', ' Europe.', ' Japan.', ' US.',\n",
       "       ' US.', ' US.', ' US.', ' US.', ' Japan.', ' US.', ' US.',\n",
       "       ' Europe.', ' US.', ' Japan.', ' US.', ' Europe.', ' Japan.',\n",
       "       ' US.', ' Europe.', ' Japan.', ' US.', ' US.', ' US.', ' Europe.',\n",
       "       ' US.', ' Europe.', ' Japan.', ' US.', ' US.', ' US.', ' Japan.',\n",
       "       ' Japan.', ' Europe.', ' US.', ' US.', ' Europe.', ' Japan.',\n",
       "       ' US.', ' US.', ' US.', ' Japan.', ' US.', ' US.', ' US.', ' US.',\n",
       "       ' US.', ' Japan.', ' US.', ' Europe.', ' US.', ' Europe.',\n",
       "       ' Europe.', ' US.', ' Japan.', ' US.', ' Europe.', ' US.',\n",
       "       ' Europe.', ' Europe.', ' Europe.', ' Europe.', ' US.', ' US.',\n",
       "       ' Japan.', ' Japan.', ' US.', ' US.', ' Europe.', ' US.',\n",
       "       ' Europe.', ' Europe.', ' Europe.', ' US.', ' US.', ' Japan.',\n",
       "       ' US.', ' US.', ' US.', ' US.', ' US.', ' US.', ' US.', ' Japan.',\n",
       "       ' US.', ' US.', ' US.', ' US.', ' US.', ' US.', ' Europe.', ' US.',\n",
       "       ' US.', ' US.', ' US.', ' US.', ' Japan.', ' Japan.', ' Europe.',\n",
       "       ' US.', ' Japan.', ' US.', ' US.', ' US.', ' US.', ' US.', ' US.',\n",
       "       ' Europe.', ' Japan.', ' US.', ' Europe.', ' Europe.', ' US.',\n",
       "       ' US.', ' US.', ' Europe.', ' Europe.', ' Japan.', ' US.', ' US.',\n",
       "       ' US.', ' US.', ' US.', ' Japan.', ' US.', ' US.', ' Europe.',\n",
       "       ' US.', ' US.', ' Japan.', ' US.', ' Japan.', ' US.', ' Japan.',\n",
       "       ' US.', ' Japan.', ' US.', ' US.', ' US.', ' Europe.', ' Europe.',\n",
       "       ' US.', ' Japan.', ' US.', ' US.', ' US.', ' Europe.', ' US.',\n",
       "       ' Japan.', ' US.', ' US.', ' Europe.', ' Europe.', ' Europe.',\n",
       "       ' Europe.', ' US.', ' US.', ' Europe.', ' US.', ' US.', ' US.',\n",
       "       ' Europe.', ' US.', ' US.', ' US.', ' US.'], dtype=object)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9c46bd26-f6a0-4861-9058-95f8a2eb128d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sklearn: 0.9945054945054945\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy sklearn:\",metrics.accuracy_score(train_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4eda67a8-0678-4e06-8191-f3e887ca225b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.tree_.node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee62d0b7-7de9-409c-a1b0-aee55b1bce27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
